{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnunS-BuwN2H"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install -q torch torchvision timm mlflow pyngrok pytorch-lightning==2.4.0\n",
        "!pip install -q \"huggingface-hub<1.0\" \"transformers<4.44\" torchmetrics==1.4.0 scikit-learn numpy matplotlib seaborn\n",
        "\n",
        "# CLEAN CACHE (optional but recommended for fresh installs/updates)\n",
        "import os, shutil\n",
        "if os.path.exists(\"/root/.cache/huggingface/hub\"):\n",
        "    shutil.rmtree(\"/root/.cache/huggingface/hub\")\n",
        "\n",
        "# ===============================\n",
        "# ğŸ“ System & File Handling\n",
        "# ===============================\n",
        "import os                    # OS operations (paths, env vars)\n",
        "import shutil                # High-level file operations\n",
        "from pathlib import Path     # Clean path handling\n",
        "\n",
        "# ===============================\n",
        "# ğŸ–¼ Image Processing\n",
        "# ===============================\n",
        "from PIL import Image        # Image loading & processing\n",
        "\n",
        "# ===============================\n",
        "# ğŸ”¥ PyTorch Core\n",
        "# ===============================\n",
        "import torch                 # Core PyTorch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# ===============================\n",
        "# âš¡ PyTorch Lightning\n",
        "# ===============================\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "# ===============================\n",
        "# ğŸ§  Vision & Transforms\n",
        "# ===============================\n",
        "from torchvision import datasets, transforms\n",
        "import timm                  # Pretrained vision models (EfficientNet, ViT, ConvNeXt)\n",
        "\n",
        "# ===============================\n",
        "# ğŸ“Š Experiment Tracking (MLflow)\n",
        "# ===============================\n",
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "\n",
        "# ===============================\n",
        "# ğŸŒ Public MLflow UI (ngrok)\n",
        "# ===============================\n",
        "from pyngrok import ngrok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This line checks whether a GPU (CUDA) is available.\n",
        "# If a GPU exists, training will run on the GPU for much faster performance.\n",
        "# If no GPU is found (e.g., running on CPU-only machine), it will fall back to CPU.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Print which device the model will use\n",
        "print(\"Running on:\", device)"
      ],
      "metadata": {
        "id": "3-LqLBeeiTM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iYiAzeQ3imvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Kj0XgzlDjvRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eq8RfxpzwoTU"
      },
      "outputs": [],
      "source": [
        "# =============================\n",
        "# ğŸ”§ USER CONFIGURATION\n",
        "# (Edit these values according to your project)\n",
        "# =============================\n",
        "\n",
        "# ğŸ‘‰ Your Ngrok authentication token (required to create a public URL for MLflow UI)\n",
        "# âš ï¸ Keep this private. Anyone with this token can use your ngrok account.\n",
        "NGROK_AUTH_TOKEN = \"36CLviJ3eedsGnzgPHm7MM9g4De_4tDSxH3CgGEQCytxcXKgX\"\n",
        "\n",
        "# ğŸ‘‰ Directory where MLflow will store run logs, metrics, parameters, and model artifacts\n",
        "MLRUNS_DIR = \"/content/drive/MyDrive/BongoDev/Project-1/mlruns\"\n",
        "\n",
        "# ğŸ‘‰ Path to your dataset ZIP file (usually stored in Google Drive)\n",
        "# ML pipeline will unzip and prepare the dataset from here.\n",
        "DATA_ZIP = \"/content/drive/MyDrive/BongoDev/Project-1/archive.zip\"\n",
        "\n",
        "# ğŸ‘‰ Directory where the dataset should be extracted\n",
        "EXTRACT_DIR = \"/content/drive/MyDrive/BongoDev/Project-1/Potato\"\n",
        "\n",
        "# ğŸ‘‰ Image size for training (input size for vision models like ViT, EfficientNet, ResNet)\n",
        "IMG_SIZE = 224\n",
        "\n",
        "# ğŸ‘‰ Number of images per batch during training\n",
        "# Higher batch size â†’ faster training but requires more GPU memory\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# ğŸ‘‰ Maximum number of epochs the model will train\n",
        "# One epoch = one full pass over the entire dataset\n",
        "MAX_EPOCHS = 2\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "# pyngrok â†’ a Python wrapper for ngrok, allowing you to create public URLs\n",
        "#            for local services (like MLflow UI) directly from code.\n",
        "\n",
        "ngrok.kill()\n",
        "# This command closes ALL existing ngrok tunnels.\n",
        "# Why?\n",
        "# - Prevents \"address already in use\" errors\n",
        "# - Ensures a clean state before creating a new ngrok tunnel\n",
        "# - Useful in Google Colab where old tunnels may stay alive across runs"
      ],
      "metadata": {
        "id": "Xu1jHgsXloK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def start_mlflow_ui(port: int = 5000, mlruns_dir: str = MLRUNS_DIR):\n",
        "\n",
        "    # -----------------------------------------\n",
        "    # Create the MLflow directory if not exists\n",
        "    # -----------------------------------------\n",
        "    os.makedirs(mlruns_dir, exist_ok=True)\n",
        "    # MLflow stores metrics, params, and artifacts under this folder.\n",
        "\n",
        "\n",
        "    # -----------------------------------------\n",
        "    # Kill previous MLflow + ngrok processes\n",
        "    # Ensures a clean start (very important in Colab)\n",
        "    # -----------------------------------------\n",
        "    try:\n",
        "        get_ipython().system_raw(\"pkill -f mlflow\")\n",
        "        # Kills any process related to \"mlflow ui\" running in the background\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    try:\n",
        "        ngrok.kill()\n",
        "        # Closes ALL running ngrok tunnels, preventing port conflicts\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "\n",
        "    # -----------------------------------------\n",
        "    # Add your NGROK auth token (required for tunnels)\n",
        "    # -----------------------------------------\n",
        "    os.system(f\"ngrok config add-authtoken {NGROK_AUTH_TOKEN}\")\n",
        "    # Registers your ngrok token so tunnels work under your account.\n",
        "\n",
        "\n",
        "    # -----------------------------------------\n",
        "    # FIX 1: Host header rewrite\n",
        "    # Required because MLflow runs on a different internal URL.\n",
        "    # This prevents 502 Bad Gateway errors.\n",
        "    # -----------------------------------------\n",
        "    os.system(\"mkdir -p /root/.ngrok2\")\n",
        "    os.system(\"echo 'host_header: rewrite' >> /root/.ngrok2/ngrok.yml\")\n",
        "\n",
        "\n",
        "    # -----------------------------------------\n",
        "    # Start MLflow UI in the background\n",
        "    # -----------------------------------------\n",
        "    get_ipython().system_raw(\n",
        "        f\"nohup mlflow ui \"\n",
        "        f\"--backend-store-uri file:{mlruns_dir} \"  # Where mlruns are stored\n",
        "        f\"--port {port} \"                          # Local MLflow port\n",
        "        f\"--host 0.0.0.0 \"                         # Expose it for ngrok\n",
        "        f\"> /content/mlflow.log 2>&1 &\"            # Log output to file\n",
        "    )\n",
        "\n",
        "    time.sleep(3)  # Wait for MLflow to start\n",
        "\n",
        "\n",
        "    # -----------------------------------------\n",
        "    # FIX 2: Use host_header=\"rewrite\"\n",
        "    # Required to make MLflow UI accessible via ngrok\n",
        "    # -----------------------------------------\n",
        "    public_url = ngrok.connect(port, \"http\", host_header=\"rewrite\")\n",
        "\n",
        "\n",
        "    # -----------------------------------------\n",
        "    # Return public MLflow tracking URL\n",
        "    # -----------------------------------------\n",
        "    print(\"Your MLflow Tracking URL:\", public_url)\n",
        "\n",
        "    return public_url"
      ],
      "metadata": {
        "id": "lNqTTnkPmFGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os  # File/folder operations (join paths, check existence)\n",
        "import pytorch_lightning as pl  # Lightning framework for structured training\n",
        "from torch.utils.data import DataLoader  # Wraps datasets into batches with shuffle & workers\n",
        "from torchvision import datasets, transforms  # Dataset loading & image preprocessing\n",
        "\n",
        "# ----------------------------------------\n",
        "# LightningDataModule for Plant Disease Dataset\n",
        "# ----------------------------------------\n",
        "class PlantDataModule(pl.LightningDataModule):\n",
        "\n",
        "    def __init__(self, data_dir, batch_size=32, img_size=224):\n",
        "        \"\"\"\n",
        "        Initialize the DataModule.\n",
        "        Args:\n",
        "            data_dir (str): Root path to dataset\n",
        "            batch_size (int): Images per batch\n",
        "            img_size (int): Resize images to square size\n",
        "        \"\"\"\n",
        "        super().__init__()  # Initialize LightningDataModule\n",
        "        self.data_dir = data_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "\n",
        "        # -------------------------------\n",
        "        # Transformations for training images\n",
        "        # -------------------------------\n",
        "        self.train_tfms = transforms.Compose([\n",
        "            transforms.Resize((img_size, img_size)),\n",
        "            transforms.RandomResizedCrop(img_size, scale=(0.8, 1.0)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(15),\n",
        "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                               std=[0.229, 0.224, 0.225])                     # Convert PIL Image â†’ PyTorch Tensor\n",
        "        ])\n",
        "\n",
        "        # -------------------------------\n",
        "        # Transformations for validation/test images\n",
        "        # -------------------------------\n",
        "        self.val_tfms = transforms.Compose([\n",
        "            transforms.Resize((img_size, img_size)),  # Resize all images\n",
        "            transforms.ToTensor()                     # Convert PIL Image â†’ PyTorch Tensor\n",
        "        ])\n",
        "\n",
        "    # -------------------------------\n",
        "    # Setup datasets (train/val/test)\n",
        "    # -------------------------------\n",
        "    def setup(self, stage=None):\n",
        "        \"\"\"\n",
        "        Called by Lightning at the start of training/validation/testing.\n",
        "        Loads datasets using ImageFolder.\n",
        "        \"\"\"\n",
        "        train_dir = os.path.join(self.data_dir, \"Train\")  # Path to training images\n",
        "        val_dir = os.path.join(self.data_dir, \"Valid\")    # Path to validation images\n",
        "        test_dir = os.path.join(self.data_dir, \"Test\")    # Path to test images\n",
        "\n",
        "        # Safety check: training folder must exist\n",
        "        if not os.path.exists(train_dir):\n",
        "            raise FileNotFoundError(f\"Expected train folder at {train_dir}\")\n",
        "\n",
        "        # Load datasets\n",
        "        self.train_ds = datasets.ImageFolder(train_dir, transform=self.train_tfms)\n",
        "        self.val_ds = datasets.ImageFolder(val_dir, transform=self.val_tfms) if os.path.exists(val_dir) else None\n",
        "        self.test_ds = datasets.ImageFolder(test_dir, transform=self.val_tfms) if os.path.exists(test_dir) else None\n",
        "\n",
        "    # -------------------------------\n",
        "    # Training DataLoader\n",
        "    # -------------------------------\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_ds,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,  # Shuffle each epoch for better generalization\n",
        "            num_workers=2  # Parallel data loading\n",
        "        )\n",
        "\n",
        "    # -------------------------------\n",
        "    # Validation DataLoader\n",
        "    # -------------------------------\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.val_ds,\n",
        "            batch_size=self.batch_size,\n",
        "            num_workers=2\n",
        "        ) if self.val_ds else None  # Returns None if no validation dataset\n",
        "\n",
        "    # -------------------------------\n",
        "    # Test DataLoader\n",
        "    # -------------------------------\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.test_ds,\n",
        "            batch_size=self.batch_size,\n",
        "            num_workers=2\n",
        "        ) if self.test_ds else None  # Returns None if no test dataset"
      ],
      "metadata": {
        "id": "SigUVF-ABb5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# ğŸŒ± PlantDiseaseModel â€” PyTorch Lightning Module\n",
        "# =====================================================\n",
        "\n",
        "import pytorch_lightning as pl  # Lightning framework for structured training\n",
        "import torch                     # Core PyTorch library\n",
        "import timm                      # Library with SOTA pretrained vision models\n",
        "\n",
        "# -------------------------------\n",
        "# Learning rate\n",
        "# -------------------------------\n",
        "\n",
        "# -------------------------------\n",
        "# LightningModule for Plant Disease Classification\n",
        "# -------------------------------\n",
        "class PlantDiseaseModel(pl.LightningModule):\n",
        "    def __init__(self, model_name=\"efficientnet_b0\", lr=1e-4, num_classes=3):\n",
        "        \"\"\"\n",
        "        Plant Disease Classification Model using timm pretrained backbone\n",
        "\n",
        "        Args:\n",
        "            model_name (str): timm model identifier (e.g. 'efficientnet_b0', 'resnet50', 'convnext_tiny')\n",
        "            lr (float): initial learning rate\n",
        "            num_classes (int): number of plant disease classes\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        # Model backbone\n",
        "        self.backbone = timm.create_model(\n",
        "            model_name,\n",
        "            pretrained=True,\n",
        "            num_classes=num_classes,          # replaces classifier head\n",
        "            drop_rate=0.3                     # light dropout in classifier\n",
        "        )\n",
        "\n",
        "        # Loss function\n",
        "        self.loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=0.1)  # <-- small label smoothing often helps\n",
        "\n",
        "        # For manual collection â†’ later plotting\n",
        "        self.train_losses = []\n",
        "        self.train_accs   = []\n",
        "        self.val_losses   = []\n",
        "        self.val_accs     = []\n",
        "\n",
        "        # We'll also keep epoch-level averages for cleaner plots\n",
        "        self.train_loss_epoch = []\n",
        "        self.train_acc_epoch  = []\n",
        "        self.val_loss_epoch   = []\n",
        "        self.val_acc_epoch    = []\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.loss_fn(logits, y)\n",
        "\n",
        "        # Accuracy\n",
        "        preds = logits.argmax(dim=1)\n",
        "        acc = (preds == y).float().mean()\n",
        "\n",
        "        # Logging (per step / batch)\n",
        "        self.log(\"train_loss\", loss, prog_bar=True, sync_dist=True)\n",
        "        self.log(\"train_acc\",  acc,  prog_bar=True, sync_dist=True)\n",
        "\n",
        "        # Collect for plotting\n",
        "        self.train_losses.append(loss.item())\n",
        "        self.train_accs.append(acc.item())\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.loss_fn(logits, y)\n",
        "\n",
        "        preds = logits.argmax(dim=1)\n",
        "        acc = (preds == y).float().mean()\n",
        "\n",
        "        self.log(\"val_loss\", loss, prog_bar=True, sync_dist=True)\n",
        "        self.log(\"val_acc\",  acc,  prog_bar=True, sync_dist=True)\n",
        "\n",
        "        self.val_losses.append(loss.item())\n",
        "        self.val_accs.append(acc.item())\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.loss_fn(logits, y)\n",
        "\n",
        "        preds = logits.argmax(dim=1)\n",
        "        acc = (preds == y).float().mean()\n",
        "\n",
        "        self.log(\"test_loss\", loss, prog_bar=True)\n",
        "        self.log(\"test_acc\",  acc,  prog_bar=True)\n",
        "\n",
        "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
        "        \"\"\"Used with trainer.predict() â€” returns probabilities or logits\"\"\"\n",
        "        x, _ = batch\n",
        "        logits = self(x)\n",
        "        return logits.softmax(dim=1)   # â† usually better to return probabilities\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    #  Epoch-end hooks â†’ compute & store average metrics\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    def on_train_epoch_end(self):\n",
        "        if len(self.train_losses) > 0:\n",
        "            avg_loss = sum(self.train_losses) / len(self.train_losses)\n",
        "            avg_acc  = sum(self.train_accs)  / len(self.train_accs)\n",
        "\n",
        "            self.train_loss_epoch.append(avg_loss)\n",
        "            self.train_acc_epoch.append(avg_acc)\n",
        "\n",
        "            # Optional: print or log epoch average\n",
        "            self.log(\"train_loss_epoch\", avg_loss, prog_bar=False)\n",
        "            self.log(\"train_acc_epoch\",  avg_acc,  prog_bar=False)\n",
        "\n",
        "            # Clear batch-wise lists (optional - depends if you want all history)\n",
        "            # self.train_losses.clear()\n",
        "            # self.train_accs.clear()\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        if len(self.val_losses) > 0:\n",
        "            avg_loss = sum(self.val_losses) / len(self.val_losses)\n",
        "            avg_acc  = sum(self.val_accs)  / len(self.val_accs)\n",
        "\n",
        "            self.val_loss_epoch.append(avg_loss)\n",
        "            self.val_acc_epoch.append(avg_acc)\n",
        "\n",
        "            self.log(\"val_loss_epoch\", avg_loss, prog_bar=False)\n",
        "            self.log(\"val_acc_epoch\",  avg_acc,  prog_bar=False)\n",
        "\n",
        "            # self.val_losses.clear()\n",
        "            # self.val_accs.clear()\n",
        "    # -------------------------------\n",
        "    # Optimizer configuration\n",
        "    # -------------------------------\n",
        "    def configure_optimizers(self):\n",
        "      optimizer = torch.optim.Adam(\n",
        "          self.parameters(),\n",
        "          lr=self.hparams.lr\n",
        "      )\n",
        "\n",
        "      scheduler = {\n",
        "          \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "              optimizer,\n",
        "              mode=\"min\",      # val_loss à¦•à¦®à¦¾à¦¨à§‹ à¦²à¦•à§à¦·à§à¦¯\n",
        "              factor=0.5,      # lr = lr * 0.5\n",
        "              patience=3       # 3 epoch wait à¦•à¦°à¦¬à§‡\n",
        "          ),\n",
        "          \"monitor\": \"val_loss\",\n",
        "          \"interval\": \"epoch\",\n",
        "          \"frequency\": 1\n",
        "      }\n",
        "\n",
        "      return {\n",
        "          \"optimizer\": optimizer,\n",
        "          \"lr_scheduler\": scheduler\n",
        "      }"
      ],
      "metadata": {
        "id": "9urjPP5zIq5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Preparing data module and model (this will error if your dataset path is wrong)...\")\n",
        "dm = PlantDataModule(EXTRACT_DIR)\n",
        "\n",
        "try:\n",
        "    dm.setup()\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Data setup failed: {e}\")\n",
        "\n",
        "num_classes = len(dm.train_ds.classes)\n",
        "print(\"Classes:\", dm.train_ds.classes)\n",
        "\n",
        "model = PlantDiseaseModel(num_classes=num_classes)"
      ],
      "metadata": {
        "id": "LdTGy6tTMvFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = os.path.join(\n",
        "    os.getcwd(), \"checkpoints\", \"/content/drive/MyDrive/BongoDev/Project-1/model.pth\"\n",
        ")"
      ],
      "metadata": {
        "id": "K5lNm9LAwIPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(checkpoint_path):\n",
        "    model.load_state_dict(torch.load(checkpoint_path))\n",
        "    print(\"Model loaded successfully from checkpoints.\")"
      ],
      "metadata": {
        "id": "sq6ZA0NQwPhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = pl.Trainer(\n",
        "    max_epochs=15,\n",
        ")\n",
        "\n",
        "trainer.fit(model, dm)"
      ],
      "metadata": {
        "id": "iOQ2lSYD0S64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVE MODEL HERE\n",
        "MODEL_PATH = \"/content/drive/MyDrive/BongoDev/Project-1/model.pth\"\n",
        "# Use the model's state_dict() for saving the raw weights\n",
        "torch.save(model.state_dict(), MODEL_PATH)\n",
        "print(\"Model saved at:\", MODEL_PATH)\n",
        "\n",
        "num_classes = len(dm.train_ds.classes)\n",
        "num_classes"
      ],
      "metadata": {
        "id": "HbVXAkc13cyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you collected per-epoch averages â€” or just plot what you have\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(model.train_losses, label='Train loss (per batch)', alpha=0.6)\n",
        "plt.plot(model.val_losses,   label='Val loss', marker='o')\n",
        "plt.title(\"Loss Curves\")\n",
        "plt.xlabel(\"Batch / Epoch\")\n",
        "plt.ylabel(\"CrossEntropy Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(model.train_accs, label='Train acc (per batch)', alpha=0.6)\n",
        "plt.plot(model.val_accs,   label='Val acc', marker='o')\n",
        "plt.title(\"Accuracy Curves\")\n",
        "plt.xlabel(\"Batch / Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wyrhJNyj3mgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model.eval()\n",
        "model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "test_dl = dm.test_dataloader()\n",
        "if test_dl is None:\n",
        "    print(\"No test set found â†’ using validation set\")\n",
        "    test_dl = dm.val_dataloader()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_dl:\n",
        "        x, y = batch\n",
        "        x = x.to(model.device)\n",
        "        logits = model(x)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(y.cpu().numpy())\n",
        "\n",
        "# Create & plot\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=dm.train_ds.classes)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "disp.plot(cmap='Blues', xticks_rotation=45)\n",
        "plt.title(\"Confusion Matrix (Test set)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Or with seaborn (nicer for many classes)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=dm.train_ds.classes,\n",
        "            yticklabels=dm.train_ds.classes)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9dq1WyEF3rJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install grad-cam"
      ],
      "metadata": {
        "id": "7hfrL1t_4eQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "#  Requirements (run once if needed)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# !pip install grad-cam -q\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "#  Configuration\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "image_paths = [\n",
        "    \"/content/drive/MyDrive/BongoDev/Project-1/na1.jpg\",\n",
        "    \"/content/drive/MyDrive/BongoDev/Project-1/na.JPG\",\n",
        "    \"/content/drive/MyDrive/BongoDev/Project-1/na2.JPG\",\n",
        "]\n",
        "\n",
        "# Suggested labels â€” change them based on what you expect / actual images\n",
        "image_labels = [\"Sample 1\", \"Sample 2\", \"Sample 3\"]\n",
        "\n",
        "# Target layer â€” try this first; if error occurs, switch to [model.backbone.features[-1]]\n",
        "target_layers = [model.backbone.conv_head]\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "#  Prepare Grad-CAM\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "device = next(model.parameters()).device\n",
        "model.eval()\n",
        "\n",
        "cam = GradCAM(model=model, target_layers=target_layers)\n",
        "val_transform = dm.val_tfms\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "#  Visualization with arrows pointing to most important region\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "fig, axes = plt.subplots(1, 3, figsize=(16, 6), dpi=130)\n",
        "fig.suptitle(\"Grad-CAM: Where the Model is Looking (Arrow = Strongest Attention)\",\n",
        "             fontsize=16, fontweight='bold', y=1.04)\n",
        "\n",
        "for idx, (img_path, label) in enumerate(zip(image_paths, image_labels)):\n",
        "    try:\n",
        "        # Load image\n",
        "        img_pil = Image.open(img_path).convert(\"RGB\")\n",
        "        img_tensor = val_transform(img_pil).unsqueeze(0).to(device)\n",
        "\n",
        "        # Predict\n",
        "        with torch.no_grad():\n",
        "            logits = model(img_tensor)\n",
        "            pred_class_idx = logits.argmax(dim=1).item()\n",
        "            pred_class_name = dm.train_ds.classes[pred_class_idx]\n",
        "            confidence = torch.softmax(logits, dim=1)[0, pred_class_idx].item()\n",
        "\n",
        "        # Grad-CAM\n",
        "        targets = [ClassifierOutputTarget(pred_class_idx)]\n",
        "        grayscale_cam = cam(input_tensor=img_tensor, targets=targets)\n",
        "        grayscale_cam = grayscale_cam[0, :]\n",
        "\n",
        "        # Overlay\n",
        "        img_np = np.array(img_pil.resize((224, 224))) / 255.0\n",
        "        visualization = show_cam_on_image(img_np, grayscale_cam, use_rgb=True)\n",
        "\n",
        "        # â”€â”€â”€ Find the position of maximum activation â”€â”€â”€\n",
        "        h, w = grayscale_cam.shape\n",
        "        max_y, max_x = np.unravel_index(np.argmax(grayscale_cam), grayscale_cam.shape)\n",
        "\n",
        "        # Convert to image coordinates (0â€“223 range)\n",
        "        arrow_x = max_x\n",
        "        arrow_y = max_y\n",
        "\n",
        "        # Plot image + heatmap overlay\n",
        "        ax = axes[idx]\n",
        "        ax.imshow(visualization)\n",
        "\n",
        "        # â”€â”€â”€ Draw arrow pointing to hottest spot â”€â”€â”€\n",
        "        ax.annotate(\n",
        "            \"\",\n",
        "            xy=(arrow_x, arrow_y),               # where arrow points TO\n",
        "            xytext=(arrow_x + 60, arrow_y - 60), # where arrow starts FROM (tail)\n",
        "            arrowprops=dict(\n",
        "                facecolor='red',\n",
        "                edgecolor='darkred',\n",
        "                width=4,           # thick line\n",
        "                headwidth=14,      # big arrow head\n",
        "                headlength=18,\n",
        "                shrink=0.08,       # slight shrink so tip touches exactly\n",
        "                alpha=0.9,\n",
        "                linewidth=1.5,\n",
        "                zorder=10\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Add small circle at the exact hotspot (helps visibility)\n",
        "        ax.plot(arrow_x, arrow_y, marker='o', markersize=14,\n",
        "                color='red', markeredgecolor='white', markeredgewidth=2.5, zorder=11)\n",
        "\n",
        "        # Title with prediction info\n",
        "        ax.set_title(f\"{label}\\nPred: {pred_class_name}\\nConf: {confidence:.1%}\",\n",
        "                     fontsize=11, pad=12, fontweight='medium')\n",
        "        ax.axis('off')\n",
        "\n",
        "    except Exception as e:\n",
        "        ax = axes[idx]\n",
        "        ax.text(0.5, 0.5, f\"Error\\n{str(e)[:60]}...\",\n",
        "                ha='center', va='center', color='red', fontsize=10)\n",
        "        ax.axis('off')\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1B2M9y8B6MuL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}