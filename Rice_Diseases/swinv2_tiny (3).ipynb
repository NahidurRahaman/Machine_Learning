{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "cell_execution_strategy": "setup",
      "generative_ai_disabled": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnunS-BuwN2H"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch torchvision timm mlflow pyngrok pytorch-lightning==2.4.0\n",
        "!pip install -q \"huggingface-hub<1.0\" \"transformers<4.44\" torchmetrics==1.4.0 scikit-learn numpy matplotlib seaborn\n",
        "\n",
        "import os, shutil\n",
        "if os.path.exists(\"/root/.cache/huggingface/hub\"):\n",
        "    shutil.rmtree(\"/root/.cache/huggingface/hub\")\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "import timm\n",
        "\n",
        "\n",
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "\n",
        "from pyngrok import ngrok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Running on:\", device)"
      ],
      "metadata": {
        "id": "3-LqLBeeiTM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Kj0XgzlDjvRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eq8RfxpzwoTU"
      },
      "outputs": [],
      "source": [
        "\n",
        "NGROK_AUTH_TOKEN = \"36CLviJ3eedsGnzgPHm7MM9g4De_4tDSxH3CgGEQCytxcXKgX\"\n",
        "\n",
        "\n",
        "MLRUNS_DIR = \"/content/drive/MyDrive/BongoDev/Project-1/mlruns\"\n",
        "\n",
        "DATA_ZIP = \"/content/drive/MyDrive/BongoDev/Project-1/archive.zip\"\n",
        "\n",
        "EXTRACT_DIR = \"/content/drive/MyDrive/BongoDev/Project-1/RiceLeafsDisease\"\n",
        "\n",
        "IMG_SIZE = 256\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "MAX_EPOCHS = 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pytorch_lightning as pl\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "\n",
        "class PlantDataModule(pl.LightningDataModule):\n",
        "\n",
        "    def __init__(self, data_dir, batch_size=32, img_size=256):\n",
        "\n",
        "        super().__init__()\n",
        "        self.data_dir = data_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "\n",
        "        self.train_tfms = transforms.Compose([\n",
        "            transforms.Resize((img_size, img_size)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(degrees=30),\n",
        "            transforms.RandomAffine(\n",
        "                degrees=0,\n",
        "                translate=(0.1, 0.1),\n",
        "                scale=(0.8, 1.2),\n",
        "                shear=10\n",
        "            ),\n",
        "            transforms.ColorJitter(\n",
        "                brightness=0.3,\n",
        "                contrast=0.3,\n",
        "                saturation=0.3,\n",
        "                hue=0.1\n",
        "            ),\n",
        "\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "        self.val_tfms = transforms.Compose([\n",
        "            transforms.Resize((img_size, img_size)),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "\n",
        "        train_dir = os.path.join(self.data_dir, \"train\")\n",
        "        val_dir = os.path.join(self.data_dir, \"validation\")\n",
        "        test_dir = os.path.join(self.data_dir, \"validation\")\n",
        "\n",
        "\n",
        "        if not os.path.exists(train_dir):\n",
        "            raise FileNotFoundError(f\"Expected train folder at {train_dir}\")\n",
        "\n",
        "\n",
        "        self.train_ds = datasets.ImageFolder(train_dir, transform=self.train_tfms)\n",
        "        self.val_ds = datasets.ImageFolder(val_dir, transform=self.val_tfms) if os.path.exists(val_dir) else None\n",
        "        self.test_ds = datasets.ImageFolder(test_dir, transform=self.val_tfms) if os.path.exists(test_dir) else None\n",
        "\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_ds,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=2\n",
        "        )\n",
        "\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.val_ds,\n",
        "            batch_size=self.batch_size,\n",
        "            num_workers=2\n",
        "        ) if self.val_ds else None\n",
        "\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.test_ds,\n",
        "            batch_size=self.batch_size,\n",
        "            num_workers=2\n",
        "        ) if self.test_ds else None"
      ],
      "metadata": {
        "id": "SigUVF-ABb5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import timm\n",
        "from torchmetrics.classification import Accuracy, F1Score\n",
        "\n",
        "\n",
        "class PlantDiseaseModel(pl.LightningModule):\n",
        "    def __init__(self,num_classes=6,lr=1e-4,weight_decay=1e-5,freeze_backbones=True):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.swin = timm.create_model(\"swinv2_tiny_window8_256.ms_in1k\",pretrained=True,num_classes=0)\n",
        "\n",
        "        self.convnext = timm.create_model(\"convnext_tiny\",pretrained=True,num_classes=0)\n",
        "\n",
        "\n",
        "        self.train_losses = []\n",
        "        self.train_accs   = []\n",
        "        self.val_losses   = []\n",
        "        self.val_accs     = []\n",
        "\n",
        "\n",
        "        self.train_loss_epoch = []\n",
        "        self.train_acc_epoch  = []\n",
        "        self.val_loss_epoch   = []\n",
        "        self.val_acc_epoch    = []\n",
        "\n",
        "\n",
        "        # Freeze backbones (initial)\n",
        "        if freeze_backbones:\n",
        "            self.freeze_all_backbones()\n",
        "\n",
        "        # Learnable attention weights (model importance)\n",
        "        self.attn_weights = nn.Parameter(torch.ones(2))\n",
        "\n",
        "\n",
        "        # Fusion Head\n",
        "        fusion_dim = self.swin.num_features + self.convnext.num_features\n",
        "\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Linear(fusion_dim, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "\n",
        "        # Loss & Metrics\n",
        "        self.criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "        self.train_acc = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
        "        self.val_acc   = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
        "        self.val_f1    = F1Score(task=\"multiclass\", num_classes=num_classes)\n",
        "\n",
        "\n",
        "    # Freeze / Unfreeze utilities\n",
        "    def freeze_all_backbones(self):\n",
        "        for m in [self.swin, self.convnext]:\n",
        "            for p in m.parameters():\n",
        "                p.requires_grad = False\n",
        "\n",
        "    def unfreeze_last_blocks(self):\n",
        "        # SwinV2: last stage\n",
        "        for p in self.swin.layers[-1].parameters():\n",
        "            p.requires_grad = True\n",
        "\n",
        "        # ConvNeXt: last block\n",
        "        for p in self.convnext.stages[-1].parameters():\n",
        "            p.requires_grad = True\n",
        "\n",
        "    # Lightning hook → AUTO CALLED\n",
        "    def on_train_epoch_start(self):\n",
        "        if self.current_epoch == 10:\n",
        "            print(\"Unfreezing last backbone blocks\")\n",
        "            self.unfreeze_last_blocks()\n",
        "\n",
        "\n",
        "    # Global Pool\n",
        "    def global_pool(self, x):\n",
        "        return x.mean(dim=[2, 3]) if x.dim() == 4 else x\n",
        "\n",
        "    # Forward\n",
        "    def forward(self, x):\n",
        "        swin_feat = self.global_pool(self.swin(x))\n",
        "        conv_feat = self.global_pool(self.convnext(x))\n",
        "\n",
        "        # Attention-based weighting\n",
        "        w = torch.softmax(self.attn_weights, dim=0)\n",
        "        swin_feat = swin_feat * w[0]\n",
        "        conv_feat = conv_feat * w[1]\n",
        "\n",
        "        fused = torch.cat([swin_feat, conv_feat], dim=1)\n",
        "        return self.fusion(fused)\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.criterion(logits, y)\n",
        "\n",
        "        # Accuracy\n",
        "        preds = logits.argmax(dim=1)\n",
        "        acc = (preds == y).float().mean()\n",
        "\n",
        "        # Logging (per step / batch)\n",
        "        self.log(\"train_loss\", loss, prog_bar=True, sync_dist=True)\n",
        "        self.log(\"train_acc\",  acc,  prog_bar=True, sync_dist=True)\n",
        "\n",
        "        # Collect for plotting\n",
        "        self.train_losses.append(loss.item())\n",
        "        self.train_accs.append(acc.item())\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.criterion(logits, y)\n",
        "\n",
        "        preds = logits.argmax(dim=1)\n",
        "        acc = (preds == y).float().mean()\n",
        "\n",
        "        self.log(\"val_loss\", loss, prog_bar=True, sync_dist=True)\n",
        "        self.log(\"val_acc\",  acc,  prog_bar=True, sync_dist=True)\n",
        "\n",
        "        self.val_losses.append(loss.item())\n",
        "        self.val_accs.append(acc.item())\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.criterion(logits, y)\n",
        "\n",
        "        preds = logits.argmax(dim=1)\n",
        "        acc = (preds == y).float().mean()\n",
        "\n",
        "        self.log(\"test_loss\", loss, prog_bar=True)\n",
        "        self.log(\"test_acc\",  acc,  prog_bar=True)\n",
        "\n",
        "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
        "        x, _ = batch\n",
        "        logits = self(x)\n",
        "        return logits.softmax(dim=1)\n",
        "\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        if len(self.train_losses) > 0:\n",
        "            avg_loss = sum(self.train_losses) / len(self.train_losses)\n",
        "            avg_acc  = sum(self.train_accs)  / len(self.train_accs)\n",
        "\n",
        "            self.train_loss_epoch.append(avg_loss)\n",
        "            self.train_acc_epoch.append(avg_acc)\n",
        "\n",
        "            # Optional: print or log epoch average\n",
        "            self.log(\"train_loss_epoch\", avg_loss, prog_bar=False)\n",
        "            self.log(\"train_acc_epoch\",  avg_acc,  prog_bar=False)\n",
        "\n",
        "\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        if len(self.val_losses) > 0:\n",
        "            avg_loss = sum(self.val_losses) / len(self.val_losses)\n",
        "            avg_acc  = sum(self.val_accs)  / len(self.val_accs)\n",
        "\n",
        "            self.val_loss_epoch.append(avg_loss)\n",
        "            self.val_acc_epoch.append(avg_acc)\n",
        "\n",
        "            self.log(\"val_loss_epoch\", avg_loss, prog_bar=False)\n",
        "            self.log(\"val_acc_epoch\",  avg_acc,  prog_bar=False)\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "      optimizer = torch.optim.Adam(\n",
        "          self.parameters(),\n",
        "          lr=self.hparams.lr\n",
        "      )\n",
        "\n",
        "      scheduler = {\n",
        "          \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "              optimizer,\n",
        "              mode=\"min\",\n",
        "              factor=0.5,\n",
        "              patience=3\n",
        "          ),\n",
        "          \"monitor\": \"val_loss\",\n",
        "          \"interval\": \"epoch\",\n",
        "          \"frequency\": 1\n",
        "      }\n",
        "\n",
        "      return {\n",
        "          \"optimizer\": optimizer,\n",
        "          \"lr_scheduler\": scheduler\n",
        "      }"
      ],
      "metadata": {
        "id": "9urjPP5zIq5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Preparing data module and model (this will error if your dataset path is wrong)...\")\n",
        "dm = PlantDataModule(EXTRACT_DIR, batch_size=BATCH_SIZE, img_size=IMG_SIZE)\n",
        "\n",
        "try:\n",
        "    dm.setup()\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Data setup failed: {e}\")\n",
        "\n",
        "num_classes = len(dm.train_ds.classes)\n",
        "print(\"Classes:\", dm.train_ds.classes)\n",
        "\n",
        "model = PlantDiseaseModel(num_classes=num_classes)"
      ],
      "metadata": {
        "id": "LdTGy6tTMvFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = os.path.join(\n",
        "    os.getcwd(), \"checkpoints\", \"/content/drive/MyDrive/BongoDev/Project-1/rice1_model.pth\"\n",
        ")"
      ],
      "metadata": {
        "id": "K5lNm9LAwIPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(checkpoint_path):\n",
        "    model.load_state_dict(torch.load(checkpoint_path))\n",
        "    print(\"Model loaded successfully from checkpoints.\")"
      ],
      "metadata": {
        "id": "sq6ZA0NQwPhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = pl.Trainer(\n",
        "    max_epochs=25,\n",
        ")\n",
        "\n",
        "trainer.fit(model, dm)"
      ],
      "metadata": {
        "id": "iOQ2lSYD0S64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(model, datamodule=dm)"
      ],
      "metadata": {
        "id": "sYyC99KBN5xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "MODEL_PATH = \"/content/drive/MyDrive/BongoDev/Project-1/rice1_model.pth\"\n",
        "torch.save(model.state_dict(), MODEL_PATH)\n",
        "print(\"Model saved at:\", MODEL_PATH)\n",
        "\n",
        "num_classes = len(dm.train_ds.classes)\n",
        "num_classes"
      ],
      "metadata": {
        "id": "HbVXAkc13cyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(model.train_loss_epoch,marker='o', label='Train loss (per batch)', alpha=0.6)\n",
        "plt.plot(model.val_loss_epoch,   label='Val loss', marker='o')\n",
        "plt.title(\"Loss Curves\")\n",
        "plt.xlabel(\"Batch / Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(model.train_acc_epoch,marker='o', label='Train acc (per batch)', alpha=0.6)\n",
        "plt.plot(model.val_acc_epoch,   label='Val acc', marker='o')\n",
        "plt.title(\"Accuracy Curves\")\n",
        "plt.xlabel(\"Batch / Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wyrhJNyj3mgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model.eval()\n",
        "model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "test_dl = dm.test_dataloader()\n",
        "if test_dl is None:\n",
        "    print(\"No test set found → using validation set\")\n",
        "    test_dl = dm.val_dataloader()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_dl:\n",
        "        x, y = batch\n",
        "        x = x.to(model.device)\n",
        "        logits = model(x)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(y.cpu().numpy())\n",
        "\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=dm.train_ds.classes)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "disp.plot(cmap='Blues', xticks_rotation=90)\n",
        "plt.title(\"Confusion Matrix (Test set)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=dm.train_ds.classes,\n",
        "            yticklabels=dm.train_ds.classes)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9dq1WyEF3rJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc"
      ],
      "metadata": {
        "id": "WAmIgP9Vdgrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "model.eval()\n",
        "model_device = next(model.parameters()).device\n",
        "model.to(model_device)\n",
        "\n",
        "all_labels = []\n",
        "all_logits = []\n",
        "\n",
        "\n",
        "current_dataloader = dm.test_dataloader()\n",
        "if current_dataloader is None:\n",
        "    print(\"No test set found, using validation set for ROC curve calculation.\")\n",
        "    current_dataloader = dm.val_dataloader()\n",
        "    if current_dataloader is None:\n",
        "        raise ValueError(\"Neither validation nor test dataloader is available. Cannot compute ROC curve.\")\n",
        "else:\n",
        "    print(\"Using test set for ROC curve calculation.\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in current_dataloader:\n",
        "        inputs = inputs.to(model_device)\n",
        "        logits = model(inputs)\n",
        "        all_logits.append(logits.cpu())\n",
        "        all_labels.append(targets.cpu())\n",
        "\n",
        "\n",
        "all_logits = torch.cat(all_logits).numpy()\n",
        "all_labels = torch.cat(all_labels).numpy()\n",
        "\n",
        "\n",
        "num_classes = len(dm.train_ds.classes)\n",
        "class_names = dm.train_ds.classes\n",
        "\n",
        "\n",
        "y_true = label_binarize(all_labels, classes=list(range(num_classes)))\n",
        "\n",
        "y_score = torch.softmax(torch.tensor(all_logits), dim=1).numpy()\n",
        "\n",
        "print(f\"Collected {len(all_labels)} samples for ROC analysis.\")\n",
        "print(f\"Shape of y_true: {y_true.shape}\")\n",
        "print(f\"Shape of y_score: {y_score.shape}\")\n"
      ],
      "metadata": {
        "id": "wAWhO17weK5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "for i in range(num_classes):\n",
        "    fpr, tpr, _ = roc_curve(y_true[:, i], y_score[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.plot(\n",
        "        fpr,\n",
        "        tpr,\n",
        "        label=f\"Class {i} (AUC = {roc_auc:.3f})\"\n",
        "    )\n",
        "\n",
        "plt.plot([0, 1], [0, 1], \"k--\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"Multiclass ROC Curve\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VnX8jgyOeMwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install grad-cam"
      ],
      "metadata": {
        "id": "7hfrL1t_4eQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17fc1546"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, precision_recall_fscore_support\n",
        "import torch\n",
        "\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "all_probs = []\n",
        "\n",
        "test_dl = dm.test_dataloader()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_dl:\n",
        "        x, y = batch\n",
        "        x = x.to(model.device)\n",
        "        logits = model(x)\n",
        "        probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
        "        preds = logits.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(y.cpu().numpy())\n",
        "        all_probs.extend(probs)\n",
        "\n",
        "\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "all_probs = np.array(all_probs)\n",
        "\n",
        "class_names = dm.train_ds.classes\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Classification Report (Precision, Recall, F1-Score)\")\n",
        "print(\"=\"*60)\n",
        "report = classification_report(all_labels, all_preds, target_names=class_names, digits=4)\n",
        "print(report)\n",
        "\n",
        "precision, recall, f1, support = precision_recall_fscore_support(all_labels, all_preds, average=None)\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "x = np.arange(len(class_names))\n",
        "width = 0.25\n",
        "\n",
        "plt.bar(x - width, precision, width, label='Precision', color='skyblue')\n",
        "plt.bar(x, recall, width, label='Recall', color='lightgreen')\n",
        "plt.bar(x + width, f1, width, label='F1-Score', color='salmon')\n",
        "\n",
        "plt.xlabel('Classes')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Per-Class Precision, Recall & F1-Score')\n",
        "plt.xticks(x, class_names, rotation=45, ha='right')\n",
        "plt.legend()\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "disp.plot(cmap='Blues', xticks_rotation=45)\n",
        "plt.title(\"Confusion Matrix (Test Set)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(all_labels, all_preds, average='macro')\n",
        "precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Summary Averages\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Macro Average    → Precision: {precision_macro:.4f} | Recall: {recall_macro:.4f} | F1: {f1_macro:.4f}\")\n",
        "print(f\"Weighted Average → Precision: {precision_weighted:.4f} | Recall: {recall_weighted:.4f} | F1: {f1_weighted:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "from pytorch_grad_cam import GradCAM, ScoreCAM\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image"
      ],
      "metadata": {
        "id": "dtXZf5Ct_n-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def swin_reshape_transform(tensor):\n",
        "    if isinstance(tensor, list):\n",
        "        tensor = tensor[0] # Assuming it's a list with a single tensor from out_indices=[3]\n",
        "\n",
        "    if tensor.ndim == 4: # Swin FeatureListNet output (B, C, H_spatial, W_spatial)\n",
        "        # This is already in (B, C, H, W) format, which ScoreCAM's upsampling expects.\n",
        "        return tensor\n",
        "\n",
        "    elif tensor.ndim == 3: # ViT tokens output (B, N, C)\n",
        "        B, N, C = tensor.shape\n",
        "        # Infer spatial dimensions (H, W) from N\n",
        "        # N could be 1 + H*W (with CLS token) or H*W (without CLS token)\n",
        "\n",
        "        H = W = 0\n",
        "        # Try to infer H, W assuming N is H*W or 1+H*W\n",
        "        if int(N**0.5) * int(N**0.5) == N: # N is a perfect square, assume no CLS token\n",
        "            H = W = int(N**0.5)\n",
        "            # Reshape from (B, N, C) to (B, C, H, W)\n",
        "            return tensor.permute(0, 2, 1).reshape(B, C, H, W)\n",
        "        elif N > 1 and int((N-1)**0.5) * int((N-1)**0.5) == (N-1): # N-1 is a perfect square, assume CLS token\n",
        "            H = W = int((N - 1)**0.5)\n",
        "            # Remove CLS token, then reshape from (B, N-1, C) to (B, C, H, W)\n",
        "            return tensor[:, 1:, :].permute(0, 2, 1).reshape(B, C, H, W)\n",
        "        else:\n",
        "            raise ValueError(f\"Cannot infer 2D spatial dimensions from 3D tensor with N={N}. Shape: {tensor.shape}\")\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected tensor dimensions for reshape_transform: {tensor.ndim}. Shape: {tensor.shape}\")"
      ],
      "metadata": {
        "id": "gcjORmTs_pHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.eval()\n",
        "\n",
        "from pytorch_grad_cam import GradCAMPlusPlus # Added this import\n",
        "\n",
        "# ─── Swin CAM (Score-CAM) ───\n",
        "swin_cam = ScoreCAM(\n",
        "    model=model,\n",
        "    target_layers=[model.swin.norm], # Changed target to the LayerNorm before the head\n",
        "    reshape_transform=swin_reshape_transform\n",
        "    # Removed 'batch_size' argument\n",
        ")\n",
        "\n",
        "# ─── convnext CAM (Grad-CAM++) ───\n",
        "# Using GradCAMPlusPlus for potentially sharper heatmaps\n",
        "eff_cam = GradCAMPlusPlus(\n",
        "    model=model,\n",
        "    target_layers=[model.convnext.stages[-1].blocks[-1]]\n",
        ")"
      ],
      "metadata": {
        "id": "HescXbkY_r4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from pytorch_grad_cam import GradCAMPlusPlus # Import GradCAMPlusPlus\n",
        "\n",
        "# --- Define a list of image paths to process ---\n",
        "image_paths = [\n",
        "    \"/content/drive/MyDrive/BongoDev/Project-1/image/bacterial_val.JPG\",\n",
        "    \"/content/drive/MyDrive/BongoDev/Project-1/image/brown_val.jpg\",\n",
        "    \"/content/drive/MyDrive/BongoDev/Project-1/image/healthy_val.jpg\",\n",
        "    \"/content/drive/MyDrive/BongoDev/Project-1/image/leaf_blast_val.jpg\",\n",
        "    \"/content/drive/MyDrive/BongoDev/Project-1/image/leaf_scald_val.jpg\",\n",
        "    \"/content/drive/MyDrive/BongoDev/Project-1/image/narrow_brown_val.jpg\"\n",
        "]\n",
        "# --- Labels matching the image paths ---\n",
        "image_labels = [\n",
        "    \"Bacterial Leaf Blight\",\n",
        "    \"Brown Spot\",\n",
        "    \"Healthy\",\n",
        "    \"Leaf Blast\",\n",
        "    \"Leaf Scald\",\n",
        "    \"Narrow Brown Spot\"\n",
        "]\n",
        "\n",
        "def norm(cam):\n",
        "    return (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)\n",
        "\n",
        "# --- Iterate through each image and generate/plot CAMs ---\n",
        "for idx, img_path in enumerate(image_paths):\n",
        "    try:\n",
        "        img_pil = Image.open(img_path).convert(\"RGB\")\n",
        "        input_tensor = dm.val_tfms(img_pil).unsqueeze(0).to(device)\n",
        "\n",
        "        # prediction\n",
        "        with torch.no_grad():\n",
        "            logits = model(input_tensor)\n",
        "            pred_idx = logits.argmax(dim=1).item()\n",
        "            confidence = torch.softmax(logits, dim=1)[0, pred_idx].item()\n",
        "        pred_class_name = dm.train_ds.classes[pred_idx] # Get class name here\n",
        "\n",
        "        targets = [ClassifierOutputTarget(pred_idx)]\n",
        "\n",
        "        # CAMs\n",
        "        cam_swin = swin_cam(input_tensor, targets)[0]\n",
        "        cam_eff  = eff_cam(input_tensor, targets)[0]\n",
        "\n",
        "        cam_swin_norm = norm(cam_swin)\n",
        "        cam_eff_norm  = norm(cam_eff)\n",
        "\n",
        "        img_np = np.array(img_pil.resize((dm.img_size, dm.img_size))) / 255.0\n",
        "\n",
        "        vis_swin = show_cam_on_image(img_np, cam_swin_norm, use_rgb=True)\n",
        "        vis_eff  = show_cam_on_image(img_np, cam_eff_norm, use_rgb=True)\n",
        "\n",
        "        # --- Plot for the current image ---\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(18, 5), dpi=140) # Changed to 3 subplots\n",
        "\n",
        "        axes[0].imshow(img_np)\n",
        "        axes[0].set_title(\"Original Image\", fontsize=12, fontweight='bold')\n",
        "        axes[0].axis(\"off\")\n",
        "\n",
        "        # Function to add arrow and title to CAM plots (modified to remove arrow)\n",
        "        def add_cam_details(ax, vis_cam, cam_norm, title_text, pred_class_name, confidence):\n",
        "            ax.imshow(vis_cam)\n",
        "            ax.set_title(f\"{title_text}\\nPred: {pred_class_name.replace('_', ' ').title()}\\nConf: {confidence:.2%}\",\n",
        "                         fontsize=12, fontweight='bold')\n",
        "            ax.axis(\"off\")\n",
        "\n",
        "        add_cam_details(axes[1], vis_swin, cam_swin_norm, \"Swin Transformer\\n(Score-CAM)\", pred_class_name, confidence)\n",
        "        add_cam_details(axes[2], vis_eff, cam_eff_norm, \"ConvNext\\n(Grad-CAM++)\", pred_class_name, confidence)\n",
        "\n",
        "        fig.suptitle(\n",
        "            f\"Hybrid CAM Analysis for Rice Leaf Disease\\nImage Shows: {image_labels[idx]} (Predicted: {pred_class_name.replace('_', ' ').title()})\",\n",
        "            fontsize=16,\n",
        "            fontweight=\"bold\",\n",
        "            y=1.02 # Adjust vertical position of main title\n",
        "        )\n",
        "\n",
        "        plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust rect to prevent suptitle overlap\n",
        "        plt.show()\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Image not found at path: {img_path}. Please check the path and try again.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred while processing {img_path}: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "id": "BiMwWE1rACWn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}