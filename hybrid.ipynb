{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NahidurRahaman/Machine_Learning/blob/main/hybrid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnunS-BuwN2H"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install -q torch torchvision timm mlflow pyngrok pytorch-lightning==2.4.0\n",
        "!pip install -q \"huggingface-hub<1.0\" \"transformers<4.44\" torchmetrics==1.4.0 scikit-learn numpy matplotlib seaborn\n",
        "\n",
        "\n",
        "import os, shutil\n",
        "if os.path.exists(\"/root/.cache/huggingface/hub\"):\n",
        "    shutil.rmtree(\"/root/.cache/huggingface/hub\")\n",
        "\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "import timm\n",
        "\n",
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "\n",
        "from pyngrok import ngrok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Running on:\", device)"
      ],
      "metadata": {
        "id": "3-LqLBeeiTM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Kj0XgzlDjvRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eq8RfxpzwoTU"
      },
      "outputs": [],
      "source": [
        "\n",
        "NGROK_AUTH_TOKEN = \"36CLviJ3eedsGnzgPHm7MM9g4De_4tDSxH3CgGEQCytxcXKgX\"\n",
        "\n",
        "MLRUNS_DIR = \"/content/drive/MyDrive/Project-1/mlruns\"\n",
        "DATA_ZIP = \"/content/drive/MyDrive/Project-1/archive.zip\"\n",
        "\n",
        "\n",
        "EXTRACT_DIR = \"/content/drive/MyDrive/Project-1/RiceLeafsDisease\"\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "MAX_EPOCHS = 15"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pytorch_lightning as pl\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "class PlantDataModule(pl.LightningDataModule):\n",
        "\n",
        "    def __init__(self, data_dir, batch_size=32, img_size=224):\n",
        "\n",
        "        super().__init__()\n",
        "        self.data_dir = data_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "\n",
        "\n",
        "        self.train_tfms = transforms.Compose([\n",
        "            transforms.Resize((img_size, img_size)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "\n",
        "        self.val_tfms = transforms.Compose([\n",
        "            transforms.Resize((img_size, img_size)),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "\n",
        "        train_dir = os.path.join(self.data_dir, \"train\")\n",
        "        val_dir = os.path.join(self.data_dir, \"validation\")\n",
        "        test_dir = os.path.join(self.data_dir, \"validation\")\n",
        "\n",
        "        if not os.path.exists(train_dir):\n",
        "            raise FileNotFoundError(f\"Expected train folder at {train_dir}\")\n",
        "\n",
        "\n",
        "        self.train_ds = datasets.ImageFolder(train_dir, transform=self.train_tfms)\n",
        "        self.val_ds = datasets.ImageFolder(val_dir, transform=self.val_tfms) if os.path.exists(val_dir) else None\n",
        "        self.test_ds = datasets.ImageFolder(test_dir, transform=self.val_tfms) if os.path.exists(test_dir) else None\n",
        "\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_ds,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=2\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.val_ds,\n",
        "            batch_size=self.batch_size,\n",
        "            num_workers=2\n",
        "        ) if self.val_ds else None\n",
        "\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.test_ds,\n",
        "            batch_size=self.batch_size,\n",
        "            num_workers=2\n",
        "        ) if self.test_ds else None"
      ],
      "metadata": {
        "id": "SigUVF-ABb5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "import timm\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "\n",
        "class TomatoHybridModel(pl.LightningModule):\n",
        "    def __init__(self, num_classes=6, lr=1e-4, weight_decay=1e-5):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.swin = timm.create_model(\n",
        "            \"swin_tiny_patch4_window7_224\",\n",
        "            pretrained=True,\n",
        "            features_only=True,\n",
        "            out_indices=[3]\n",
        "        )\n",
        "\n",
        "        self.vit = timm.create_model(\n",
        "            \"vit_base_patch16_224\",\n",
        "            pretrained=True,\n",
        "            num_classes=0\n",
        "        )\n",
        "\n",
        "        self.efficientnet = timm.create_model(\n",
        "            \"efficientnetv2_rw_s\",\n",
        "            pretrained=True,\n",
        "            num_classes=0\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.LazyLinear(1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "\n",
        "        self.criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "        self.train_acc = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
        "        self.val_acc   = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
        "\n",
        "\n",
        "        self.train_acc_history = []\n",
        "        self.val_acc_history = []\n",
        "        self.train_loss_history = []\n",
        "        self.val_loss_history = []\n",
        "\n",
        "    def forward(self, x):\n",
        "        swin_feat = self.swin(x)[-1].mean([2, 3])\n",
        "        vit_feat  = self.vit(x)\n",
        "        eff_feat  = self.efficientnet(x)\n",
        "        if eff_feat.dim() == 4:\n",
        "            eff_feat = eff_feat.mean([2, 3])\n",
        "\n",
        "        fused = torch.cat([swin_feat, vit_feat, eff_feat], dim=1)\n",
        "        return self.fusion(fused)\n",
        "\n",
        "    def training_step(self, batch, _):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.criterion(logits, y)\n",
        "        acc = self.train_acc(logits, y)\n",
        "\n",
        "        self.log(\"train_loss\", loss, prog_bar=True)\n",
        "        self.log(\"train_acc\", acc, prog_bar=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, _):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.criterion(logits, y)\n",
        "        acc = self.val_acc(logits, y)\n",
        "\n",
        "        self.log(\"val_loss\", loss, prog_bar=True)\n",
        "        self.log(\"val_acc\", acc, prog_bar=True)\n",
        "\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        self.train_acc_history.append(self.train_acc.compute().item())\n",
        "        self.train_loss_history.append(\n",
        "            self.trainer.callback_metrics[\"train_loss\"].item()\n",
        "        )\n",
        "        self.train_acc.reset()\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        self.val_acc_history.append(self.val_acc.compute().item())\n",
        "        self.val_loss_history.append(\n",
        "            self.trainer.callback_metrics[\"val_loss\"].item()\n",
        "        )\n",
        "        self.val_acc.reset()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = AdamW(\n",
        "            self.parameters(),\n",
        "            lr=self.hparams.lr,\n",
        "            weight_decay=self.hparams.weight_decay\n",
        "        )\n",
        "        scheduler = ReduceLROnPlateau(\n",
        "            optimizer, mode=\"min\", patience=3, factor=0.5\n",
        "        )\n",
        "        return {\n",
        "            \"optimizer\": optimizer,\n",
        "            \"lr_scheduler\": {\"scheduler\": scheduler, \"monitor\": \"val_loss\"}\n",
        "        }"
      ],
      "metadata": {
        "id": "9urjPP5zIq5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=5,\n",
        "    min_delta=0.001,\n",
        "    mode=\"min\",\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "fLOYue4wYfh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor=\"val_loss\",\n",
        "    dirpath=\"/content/drive/MyDrive/Project-1/checkpoints\",\n",
        "    filename=\"best_model\",\n",
        "    save_top_k=1,\n",
        "    mode=\"min\",\n",
        "    verbose=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "yRKQ3HDttHAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dm = PlantDataModule(EXTRACT_DIR, batch_size=BATCH_SIZE, img_size=224)\n",
        "\n",
        "try:\n",
        "    dm.setup()\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Data setup failed: {e}\")\n",
        "\n",
        "num_classes = len(dm.train_ds.classes)\n",
        "print(\"Classes:\", dm.train_ds.classes)"
      ],
      "metadata": {
        "id": "hxGflZYZuZAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Preparing data module and model (this will error if your dataset path is wrong)...\")\n",
        "dm = PlantDataModule(EXTRACT_DIR, batch_size=BATCH_SIZE, img_size=224)\n",
        "\n",
        "try:\n",
        "    dm.setup()\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Data setup failed: {e}\")\n",
        "\n",
        "num_classes = len(dm.train_ds.classes)\n",
        "print(\"Classes:\", dm.train_ds.classes)\n",
        "\n",
        "model = TomatoHybridModel(num_classes=num_classes)"
      ],
      "metadata": {
        "id": "6GFezjfe3tLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoints = os.path.join(\n",
        "    os.getcwd(), \"checkpoints\", \"/content/drive/MyDrive/Project-1/best_model.pth\"\n",
        ")"
      ],
      "metadata": {
        "id": "RNOj4_QB3ZBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(checkpoints):\n",
        "    model.load_state_dict(torch.load(checkpoints))\n",
        "    print(\"Model loaded successfully from checkpoints.\")"
      ],
      "metadata": {
        "id": "SIPlR2sS3cmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = pl.Trainer(\n",
        "    max_epochs=15,\n",
        ")"
      ],
      "metadata": {
        "id": "17T7z1Lv39hY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2584dd3c"
      },
      "source": [
        "trainer.fit(model, dm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Project-1/best_model.pth\"\n",
        "torch.save(model.state_dict(), MODEL_PATH)\n",
        "print(\"Model saved at:\", MODEL_PATH)\n",
        "\n",
        "num_classes = len(dm.train_ds.classes)\n",
        "num_classes"
      ],
      "metadata": {
        "id": "W6xroyF94HCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.validate(model, dm)"
      ],
      "metadata": {
        "id": "9AAppHomHhvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12, 5))\n",
        "max_loss = max(model.train_loss_history + model.val_loss_history)\n",
        "max_acc = max(model.train_acc_history + model.val_acc_history)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(model.train_loss_history,marker='o', linewidth=2, label=\"Train Loss\")\n",
        "plt.plot(model.val_loss_history,   marker='o', linewidth=2, label=\"Val Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.ylim(-0.02, 1.02)\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(model.train_acc_history, marker='o', linewidth=2, label=\"Train Accuracy\")\n",
        "plt.plot(model.val_acc_history,   marker='o', linewidth=2, label=\"Val Accuracy\")\n",
        "plt.ylim(0, 1.02)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training vs Validation Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wyrhJNyj3mgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model.eval()\n",
        "model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "test_dl = dm.test_dataloader()\n",
        "if test_dl is None:\n",
        "    print(\"No test set found → using validation set\")\n",
        "    test_dl = dm.val_dataloader()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_dl:\n",
        "        x, y = batch\n",
        "        x = x.to(model.device)\n",
        "        logits = model(x)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(y.cpu().numpy())\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=dm.train_ds.classes)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "disp.plot(cmap='Blues', xticks_rotation=45)\n",
        "plt.title(\"Confusion Matrix (Test set)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=dm.train_ds.classes,\n",
        "            yticklabels=dm.train_ds.classes)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9dq1WyEF3rJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install grad-cam"
      ],
      "metadata": {
        "id": "7hfrL1t_4eQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc"
      ],
      "metadata": {
        "id": "nT0-K_Y3smIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "model.eval()\n",
        "model_device = next(model.parameters()).device\n",
        "model.to(model_device)\n",
        "\n",
        "all_labels = []\n",
        "all_logits = []\n",
        "\n",
        "\n",
        "current_dataloader = dm.test_dataloader()\n",
        "if current_dataloader is None:\n",
        "    print(\"No test set found, using validation set for ROC curve calculation.\")\n",
        "    current_dataloader = dm.val_dataloader()\n",
        "    if current_dataloader is None:\n",
        "        raise ValueError(\"Neither validation nor test dataloader is available. Cannot compute ROC curve.\")\n",
        "else:\n",
        "    print(\"Using test set for ROC curve calculation.\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in current_dataloader:\n",
        "        inputs = inputs.to(model_device)\n",
        "        logits = model(inputs)\n",
        "        all_logits.append(logits.cpu())\n",
        "        all_labels.append(targets.cpu())\n",
        "\n",
        "\n",
        "all_logits = torch.cat(all_logits).numpy()\n",
        "all_labels = torch.cat(all_labels).numpy()\n",
        "\n",
        "\n",
        "num_classes = len(dm.train_ds.classes)\n",
        "class_names = dm.train_ds.classes\n",
        "\n",
        "\n",
        "y_true = label_binarize(all_labels, classes=list(range(num_classes)))\n",
        "\n",
        "y_score = torch.softmax(torch.tensor(all_logits), dim=1).numpy()\n",
        "\n",
        "print(f\"Collected {len(all_labels)} samples for ROC analysis.\")\n",
        "print(f\"Shape of y_true: {y_true.shape}\")\n",
        "print(f\"Shape of y_score: {y_score.shape}\")\n"
      ],
      "metadata": {
        "id": "GmkREjoysnnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "for i in range(num_classes):\n",
        "    fpr, tpr, _ = roc_curve(y_true[:, i], y_score[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.plot(\n",
        "        fpr,\n",
        "        tpr,\n",
        "        label=f\"Class {i} (AUC = {roc_auc:.3f})\"\n",
        "    )\n",
        "\n",
        "plt.plot([0, 1], [0, 1], \"k--\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"Multiclass ROC Curve\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JV8fGSNhs47v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, precision_recall_fscore_support\n",
        "import torch\n",
        "\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "all_probs = []  # optional for ROC if needed later\n",
        "\n",
        "test_dl = dm.test_dataloader()  # or dm.val_dataloader() if no test set\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_dl:\n",
        "        x, y = batch\n",
        "        x = x.to(model.device)\n",
        "        logits = model(x)\n",
        "        probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
        "        preds = logits.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(y.cpu().numpy())\n",
        "        all_probs.extend(probs)\n",
        "\n",
        "\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "all_probs = np.array(all_probs)\n",
        "\n",
        "class_names = dm.train_ds.classes\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Classification Report (Precision, Recall, F1-Score)\")\n",
        "print(\"=\"*60)\n",
        "report = classification_report(all_labels, all_preds, target_names=class_names, digits=4)\n",
        "print(report)\n",
        "\n",
        "precision, recall, f1, support = precision_recall_fscore_support(all_labels, all_preds, average=None)\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "x = np.arange(len(class_names))\n",
        "width = 0.25\n",
        "\n",
        "plt.bar(x - width, precision, width, label='Precision', color='skyblue')\n",
        "plt.bar(x, recall, width, label='Recall', color='lightgreen')\n",
        "plt.bar(x + width, f1, width, label='F1-Score', color='salmon')\n",
        "\n",
        "plt.xlabel('Classes')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Per-Class Precision, Recall & F1-Score')\n",
        "plt.xticks(x, class_names, rotation=45, ha='right')\n",
        "plt.legend()\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "disp.plot(cmap='Blues', xticks_rotation=45)\n",
        "plt.title(\"Confusion Matrix (Test Set)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(all_labels, all_preds, average='macro')\n",
        "precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Summary Averages\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Macro Average    → Precision: {precision_macro:.4f} | Recall: {recall_macro:.4f} | F1: {f1_macro:.4f}\")\n",
        "print(f\"Weighted Average → Precision: {precision_weighted:.4f} | Recall: {recall_weighted:.4f} | F1: {f1_weighted:.4f}\")"
      ],
      "metadata": {
        "id": "8W2-44EAMmWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "from pytorch_grad_cam import GradCAM, ScoreCAM\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image"
      ],
      "metadata": {
        "id": "9GQzNqdmd8J1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vit_swin_reshape_transform(tensor):\n",
        "    # If the input is a list (e.g., from FeatureListNet with features_only=True)\n",
        "    # extract the actual tensor from it.\n",
        "    if isinstance(tensor, list):\n",
        "        tensor = tensor[0] # Assuming it's a list with a single tensor from out_indices=[3]\n",
        "\n",
        "    if tensor.ndim == 4: # Swin FeatureListNet output (B, C, H_spatial, W_spatial)\n",
        "        # This is already in (B, C, H, W) format, which ScoreCAM's upsampling expects.\n",
        "        return tensor\n",
        "\n",
        "    elif tensor.ndim == 3: # ViT tokens output (B, N, C)\n",
        "        B, N, C = tensor.shape\n",
        "        # Infer spatial dimensions (H, W) from N\n",
        "        # N could be 1 + H*W (with CLS token) or H*W (without CLS token)\n",
        "\n",
        "        H = W = 0\n",
        "        # Try to infer H, W assuming N is H*W or 1+H*W\n",
        "        if int(N**0.5) * int(N**0.5) == N: # N is a perfect square, assume no CLS token\n",
        "            H = W = int(N**0.5)\n",
        "            # Reshape from (B, N, C) to (B, C, H, W)\n",
        "            return tensor.permute(0, 2, 1).reshape(B, C, H, W)\n",
        "        elif N > 1 and int((N-1)**0.5) * int((N-1)**0.5) == (N-1): # N-1 is a perfect square, assume CLS token\n",
        "            H = W = int((N - 1)**0.5)\n",
        "            # Remove CLS token, then reshape from (B, N-1, C) to (B, C, H, W)\n",
        "            return tensor[:, 1:, :].permute(0, 2, 1).reshape(B, C, H, W)\n",
        "        else:\n",
        "            raise ValueError(f\"Cannot infer 2D spatial dimensions from 3D tensor with N={N}. Shape: {tensor.shape}\")\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected tensor dimensions for reshape_transform: {tensor.ndim}. Shape: {tensor.shape}\")"
      ],
      "metadata": {
        "id": "WSC_55HDd_kD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.eval()\n",
        "\n",
        "# ─── Swin CAM (Score-CAM) ───\n",
        "swin_cam = ScoreCAM(\n",
        "    model=model,\n",
        "    target_layers=[model.swin],\n",
        "    reshape_transform=vit_swin_reshape_transform\n",
        "    # Removed 'batch_size' argument\n",
        ")\n",
        "\n",
        "# ─── ViT CAM (Score-CAM) ───\n",
        "vit_cam = ScoreCAM(\n",
        "    model=model,\n",
        "    target_layers=[model.vit.blocks[-1].norm1],\n",
        "    reshape_transform=vit_swin_reshape_transform\n",
        "    # Removed 'batch_size' argument\n",
        ")\n",
        "\n",
        "# ─── EfficientNet CAM (Grad-CAM) ───\n",
        "eff_cam = GradCAM(\n",
        "    model=model,\n",
        "    target_layers=[model.efficientnet.blocks[-1]]\n",
        ")"
      ],
      "metadata": {
        "id": "pvBuqRQJeCn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# --- Define a list of image paths to process ---\n",
        "# >>> EDIT THESE PATHS TO YOUR OWN IMAGES <<<\n",
        "image_paths = [\n",
        "    \"/content/Screenshot 2026-01-23 234242.png\", # User's provided screenshot\n",
        "    \"/content/drive/MyDrive/Project-1/image/narrow_brown.jpg\",\n",
        "    \"/content/drive/MyDrive/Project-1/image/leaf_scald.jpg\",\n",
        "    \"/content/drive/MyDrive/Project-1/image/leaf_blast.jpg\"\n",
        "]\n",
        "# >>> EDIT THESE LABELS TO MATCH YOUR IMAGE DESCRIPTIONS <<<\n",
        "image_labels = [\n",
        "    \"User Screenshot\", # Label for the screenshot\n",
        "    \"Narrow Brown Spot\",\n",
        "    \"Leaf Scald\",\n",
        "    \"Leaf Blast\"\n",
        "]\n",
        "\n",
        "def norm(cam):\n",
        "    return (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)\n",
        "\n",
        "# --- Iterate through each image and generate/plot CAMs ---\n",
        "for idx, img_path in enumerate(image_paths):\n",
        "    try:\n",
        "        img_pil = Image.open(img_path).convert(\"RGB\")\n",
        "        input_tensor = dm.val_tfms(img_pil).unsqueeze(0).to(device)\n",
        "\n",
        "        # prediction\n",
        "        with torch.no_grad():\n",
        "            logits = model(input_tensor)\n",
        "            pred_idx = logits.argmax(dim=1).item()\n",
        "            confidence = torch.softmax(logits, dim=1)[0, pred_idx].item()\n",
        "        pred_class_name = dm.train_ds.classes[pred_idx] # Get class name here\n",
        "\n",
        "        targets = [ClassifierOutputTarget(pred_idx)]\n",
        "\n",
        "        # CAMs\n",
        "        cam_swin = swin_cam(input_tensor, targets)[0]\n",
        "        cam_vit  = vit_cam(input_tensor, targets)[0]\n",
        "        cam_eff  = eff_cam(input_tensor, targets)[0]\n",
        "\n",
        "        cam_swin_norm = norm(cam_swin)\n",
        "        cam_vit_norm  = norm(cam_vit)\n",
        "        cam_eff_norm  = norm(cam_eff)\n",
        "\n",
        "        img_np = np.array(img_pil.resize((224, 224))) / 255.0\n",
        "\n",
        "        vis_swin = show_cam_on_image(img_np, cam_swin_norm, use_rgb=True)\n",
        "        vis_vit  = show_cam_on_image(img_np, cam_vit_norm, use_rgb=True)\n",
        "        vis_eff  = show_cam_on_image(img_np, cam_eff_norm, use_rgb=True)\n",
        "\n",
        "        # --- Plot for the current image ---\n",
        "        fig, axes = plt.subplots(1, 4, figsize=(22, 5), dpi=140)\n",
        "\n",
        "        axes[0].imshow(img_np)\n",
        "        axes[0].set_title(\"Original Image\", fontsize=12, fontweight='bold')\n",
        "        axes[0].axis(\"off\")\n",
        "\n",
        "        # Function to add arrow and title to CAM plots (modified to remove arrow)\n",
        "        def add_cam_details(ax, vis_cam, cam_norm, title_text, pred_class_name, confidence):\n",
        "            ax.imshow(vis_cam)\n",
        "            # Find hotspot on the normalized CAM\n",
        "            # max_y, max_x = np.unravel_index(np.argmax(cam_norm), cam_norm.shape)\n",
        "\n",
        "            # # Add arrow pointing to the hottest spot (removed as per user request)\n",
        "            # ax.annotate(\n",
        "            #     \"\",\n",
        "            #     xy=(max_x, max_y),               # where arrow points TO\n",
        "            #     xytext=(max_x + 60, max_y - 60), # where arrow starts FROM (tail)\n",
        "            #     arrowprops=dict(\n",
        "            #         facecolor='red',\n",
        "            #         edgecolor='darkred',\n",
        "            #         width=4,\n",
        "            #         headwidth=14,\n",
        "            #         headlength=18,\n",
        "            #         shrink=0.08,\n",
        "            #         alpha=0.9,\n",
        "            #         linewidth=1.5,\n",
        "            #         zorder=10\n",
        "            #     )\n",
        "            # )\n",
        "            # # Add small circle at the exact hotspot (removed as per user request)\n",
        "            # ax.plot(max_x, max_y, marker='o', markersize=14,\n",
        "            #         color='red', markeredgecolor='white', markeredgewidth=2.5, zorder=11)\n",
        "\n",
        "            ax.set_title(f\"{title_text}\\nPred: {pred_class_name.replace('_', ' ').title()}\\nConf: {confidence:.2%}\",\n",
        "                         fontsize=12, fontweight='bold')\n",
        "            ax.axis(\"off\")\n",
        "\n",
        "        add_cam_details(axes[1], vis_swin, cam_swin_norm, \"Swin Transformer\\n(Score-CAM)\", pred_class_name, confidence)\n",
        "        add_cam_details(axes[2], vis_vit, cam_vit_norm, \"Vision Transformer\\n(Score-CAM)\", pred_class_name, confidence)\n",
        "        add_cam_details(axes[3], vis_eff, cam_eff_norm, \"EfficientNetV2\\n(Grad-CAM)\", pred_class_name, confidence)\n",
        "\n",
        "\n",
        "        fig.suptitle(\n",
        "            f\"Hybrid CAM Analysis for Rice Leaf Disease\\nImage Shows: {image_labels[idx]} (Predicted: {pred_class_name.replace('_', ' ').title()})\",\n",
        "            fontsize=16,\n",
        "            fontweight=\"bold\",\n",
        "            y=1.02 # Adjust vertical position of main title\n",
        "        )\n",
        "\n",
        "        plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust rect to prevent suptitle overlap\n",
        "        plt.show()\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Image not found at path: {img_path}. Please check the path and try again.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred while processing {img_path}: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n"
      ],
      "metadata": {
        "id": "PCBoWGvKeKUc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}