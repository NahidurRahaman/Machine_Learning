{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NahidurRahaman/Machine_Learning/blob/main/hybrid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnunS-BuwN2H"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install -q torch torchvision timm mlflow pyngrok pytorch-lightning==2.4.0\n",
        "!pip install -q \"huggingface-hub<1.0\" \"transformers<4.44\" torchmetrics==1.4.0 scikit-learn numpy matplotlib seaborn\n",
        "\n",
        "# CLEAN CACHE (optional but recommended for fresh installs/updates)\n",
        "import os, shutil\n",
        "if os.path.exists(\"/root/.cache/huggingface/hub\"):\n",
        "    shutil.rmtree(\"/root/.cache/huggingface/hub\")\n",
        "\n",
        "# ===============================\n",
        "# ðŸ“ System & File Handling\n",
        "# ===============================\n",
        "import os                    # OS operations (paths, env vars)\n",
        "import shutil                # High-level file operations\n",
        "from pathlib import Path     # Clean path handling\n",
        "\n",
        "# ===============================\n",
        "# ðŸ–¼ Image Processing\n",
        "# ===============================\n",
        "from PIL import Image        # Image loading & processing\n",
        "\n",
        "# ===============================\n",
        "# ðŸ”¥ PyTorch Core\n",
        "# ===============================\n",
        "import torch                 # Core PyTorch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# ===============================\n",
        "# âš¡ PyTorch Lightning\n",
        "# ===============================\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "# ===============================\n",
        "# ðŸ§  Vision & Transforms\n",
        "# ===============================\n",
        "from torchvision import datasets, transforms\n",
        "import timm                  # Pretrained vision models (EfficientNet, ViT, ConvNeXt)\n",
        "\n",
        "# ===============================\n",
        "# ðŸ“Š Experiment Tracking (MLflow)\n",
        "# ===============================\n",
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "\n",
        "# ===============================\n",
        "# ðŸŒ Public MLflow UI (ngrok)\n",
        "# ===============================\n",
        "from pyngrok import ngrok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This line checks whether a GPU (CUDA) is available.\n",
        "# If a GPU exists, training will run on the GPU for much faster performance.\n",
        "# If no GPU is found (e.g., running on CPU-only machine), it will fall back to CPU.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Print which device the model will use\n",
        "print(\"Running on:\", device)"
      ],
      "metadata": {
        "id": "3-LqLBeeiTM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Kj0XgzlDjvRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eq8RfxpzwoTU"
      },
      "outputs": [],
      "source": [
        "# =============================\n",
        "# ðŸ”§ USER CONFIGURATION\n",
        "# (Edit these values according to your project)\n",
        "# =============================\n",
        "\n",
        "# ðŸ‘‰ Your Ngrok authentication token (required to create a public URL for MLflow UI)\n",
        "# âš ï¸ Keep this private. Anyone with this token can use your ngrok account.\n",
        "NGROK_AUTH_TOKEN = \"36CLviJ3eedsGnzgPHm7MM9g4De_4tDSxH3CgGEQCytxcXKgX\"\n",
        "\n",
        "# ðŸ‘‰ Directory where MLflow will store run logs, metrics, parameters, and model artifacts\n",
        "MLRUNS_DIR = \"/content/drive/MyDrive/Project-1/mlruns\"\n",
        "\n",
        "# ðŸ‘‰ Path to your dataset ZIP file (usually stored in Google Drive)\n",
        "# ML pipeline will unzip and prepare the dataset from here.\n",
        "DATA_ZIP = \"/content/drive/MyDrive/Project-1/archive.zip\"\n",
        "\n",
        "# ðŸ‘‰ Directory where the dataset should be extracted\n",
        "EXTRACT_DIR = \"/content/drive/MyDrive/Project-1/RiceLeafsDisease\"\n",
        "\n",
        "# ðŸ‘‰ Image size for training (input size for vision models like ViT, EfficientNet, ResNet)\n",
        "IMG_SIZE = 224\n",
        "\n",
        "# ðŸ‘‰ Number of images per batch during training\n",
        "# Higher batch size â†’ faster training but requires more GPU memory\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# ðŸ‘‰ Maximum number of epochs the model will train\n",
        "# One epoch = one full pass over the entire dataset\n",
        "MAX_EPOCHS = 15"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os  # File/folder operations (join paths, check existence)\n",
        "import pytorch_lightning as pl  # Lightning framework for structured training\n",
        "from torch.utils.data import DataLoader  # Wraps datasets into batches with shuffle & workers\n",
        "from torchvision import datasets, transforms  # Dataset loading & image preprocessing\n",
        "\n",
        "# ----------------------------------------\n",
        "# LightningDataModule for Plant Disease Dataset\n",
        "# ----------------------------------------\n",
        "class PlantDataModule(pl.LightningDataModule):\n",
        "\n",
        "    def __init__(self, data_dir, batch_size=32, img_size=224):\n",
        "        \"\"\"\n",
        "        Initialize the DataModule.\n",
        "        Args:\n",
        "            data_dir (str): Root path to dataset\n",
        "            batch_size (int): Images per batch\n",
        "            img_size (int): Resize images to square size\n",
        "        \"\"\"\n",
        "        super().__init__()  # Initialize LightningDataModule\n",
        "        self.data_dir = data_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "\n",
        "        # -------------------------------\n",
        "        # Transformations for training images\n",
        "        # -------------------------------\n",
        "        self.train_tfms = transforms.Compose([\n",
        "            transforms.Resize((img_size, img_size)),  # Resize all images\n",
        "            transforms.RandomHorizontalFlip(),        # Data augmentation: random horizontal flip\n",
        "            transforms.ToTensor()                     # Convert PIL Image â†’ PyTorch Tensor\n",
        "        ])\n",
        "\n",
        "        # -------------------------------\n",
        "        # Transformations for validation/test images\n",
        "        # -------------------------------\n",
        "        self.val_tfms = transforms.Compose([\n",
        "            transforms.Resize((img_size, img_size)),  # Resize all images\n",
        "            transforms.ToTensor()                     # Convert PIL Image â†’ PyTorch Tensor\n",
        "        ])\n",
        "\n",
        "    # -------------------------------\n",
        "    # Setup datasets (train/val/test)\n",
        "    # -------------------------------\n",
        "    def setup(self, stage=None):\n",
        "        \"\"\"\n",
        "        Called by Lightning at the start of training/validation/testing.\n",
        "        Loads datasets using ImageFolder.\n",
        "        \"\"\"\n",
        "        train_dir = os.path.join(self.data_dir, \"train\")  # Path to training images\n",
        "        val_dir = os.path.join(self.data_dir, \"validation\")    # Path to validation images\n",
        "        test_dir = os.path.join(self.data_dir, \"validation\")    # Path to test images\n",
        "\n",
        "        # Safety check: training folder must exist\n",
        "        if not os.path.exists(train_dir):\n",
        "            raise FileNotFoundError(f\"Expected train folder at {train_dir}\")\n",
        "\n",
        "        # Load datasets\n",
        "        self.train_ds = datasets.ImageFolder(train_dir, transform=self.train_tfms)\n",
        "        self.val_ds = datasets.ImageFolder(val_dir, transform=self.val_tfms) if os.path.exists(val_dir) else None\n",
        "        self.test_ds = datasets.ImageFolder(test_dir, transform=self.val_tfms) if os.path.exists(test_dir) else None\n",
        "\n",
        "    # -------------------------------\n",
        "    # Training DataLoader\n",
        "    # -------------------------------\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_ds,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,  # Shuffle each epoch for better generalization\n",
        "            num_workers=2  # Parallel data loading\n",
        "        )\n",
        "\n",
        "    # -------------------------------\n",
        "    # Validation DataLoader\n",
        "    # -------------------------------\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.val_ds,\n",
        "            batch_size=self.batch_size,\n",
        "            num_workers=2\n",
        "        ) if self.val_ds else None  # Returns None if no validation dataset\n",
        "\n",
        "    # -------------------------------\n",
        "    # Test DataLoader\n",
        "    # -------------------------------\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.test_ds,\n",
        "            batch_size=self.batch_size,\n",
        "            num_workers=2\n",
        "        ) if self.test_ds else None  # Returns None if no test dataset"
      ],
      "metadata": {
        "id": "SigUVF-ABb5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "import timm\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "\n",
        "class TomatoHybridModel(pl.LightningModule):\n",
        "    def __init__(self, num_classes=6, lr=1e-4, weight_decay=1e-5):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        # Backbone models\n",
        "        self.swin = timm.create_model(\n",
        "            \"swin_tiny_patch4_window7_224\",\n",
        "            pretrained=True,\n",
        "            features_only=True,\n",
        "            out_indices=[3]\n",
        "        )\n",
        "\n",
        "        self.vit = timm.create_model(\n",
        "            \"vit_base_patch16_224\",\n",
        "            pretrained=True,\n",
        "            num_classes=0\n",
        "        )\n",
        "\n",
        "        self.efficientnet = timm.create_model(\n",
        "            \"efficientnetv2_rw_s\",\n",
        "            pretrained=True,\n",
        "            num_classes=0\n",
        "        )\n",
        "\n",
        "        # Fusion head\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.LazyLinear(1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "        # Loss & metrics\n",
        "        self.criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "        self.train_acc = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
        "        self.val_acc   = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
        "\n",
        "        # ðŸ”¥ History storage\n",
        "        self.train_acc_history = []\n",
        "        self.val_acc_history = []\n",
        "        self.train_loss_history = []\n",
        "        self.val_loss_history = []\n",
        "\n",
        "    def forward(self, x):\n",
        "        swin_feat = self.swin(x)[-1].mean([2, 3])\n",
        "        vit_feat  = self.vit(x)\n",
        "        eff_feat  = self.efficientnet(x)\n",
        "        if eff_feat.dim() == 4:\n",
        "            eff_feat = eff_feat.mean([2, 3])\n",
        "\n",
        "        fused = torch.cat([swin_feat, vit_feat, eff_feat], dim=1)\n",
        "        return self.fusion(fused)\n",
        "\n",
        "    def training_step(self, batch, _):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.criterion(logits, y)\n",
        "        acc = self.train_acc(logits, y)\n",
        "\n",
        "        self.log(\"train_loss\", loss, prog_bar=True)\n",
        "        self.log(\"train_acc\", acc, prog_bar=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, _):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.criterion(logits, y)\n",
        "        acc = self.val_acc(logits, y)\n",
        "\n",
        "        self.log(\"val_loss\", loss, prog_bar=True)\n",
        "        self.log(\"val_acc\", acc, prog_bar=True)\n",
        "\n",
        "    # ðŸ”¥ Epoch end hooks\n",
        "    def on_train_epoch_end(self):\n",
        "        self.train_acc_history.append(self.train_acc.compute().item())\n",
        "        self.train_loss_history.append(\n",
        "            self.trainer.callback_metrics[\"train_loss\"].item()\n",
        "        )\n",
        "        self.train_acc.reset()\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        self.val_acc_history.append(self.val_acc.compute().item())\n",
        "        self.val_loss_history.append(\n",
        "            self.trainer.callback_metrics[\"val_loss\"].item()\n",
        "        )\n",
        "        self.val_acc.reset()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = AdamW(\n",
        "            self.parameters(),\n",
        "            lr=self.hparams.lr,\n",
        "            weight_decay=self.hparams.weight_decay\n",
        "        )\n",
        "        scheduler = ReduceLROnPlateau(\n",
        "            optimizer, mode=\"min\", patience=3, factor=0.5\n",
        "        )\n",
        "        return {\n",
        "            \"optimizer\": optimizer,\n",
        "            \"lr_scheduler\": {\"scheduler\": scheduler, \"monitor\": \"val_loss\"}\n",
        "        }"
      ],
      "metadata": {
        "id": "9urjPP5zIq5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=5,\n",
        "    min_delta=0.001,\n",
        "    mode=\"min\",\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "fLOYue4wYfh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor=\"val_loss\",\n",
        "    dirpath=\"/content/drive/MyDrive/Project-1/checkpoints\",\n",
        "    filename=\"best_model\",   # ðŸ”¥ .ckpt à¦¨à¦¿à¦œà§‡ à¦¯à§‹à¦— à¦¹à¦¬à§‡\n",
        "    save_top_k=1,\n",
        "    mode=\"min\",\n",
        "    verbose=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "yRKQ3HDttHAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dm = PlantDataModule(EXTRACT_DIR, batch_size=BATCH_SIZE, img_size=224)\n",
        "\n",
        "try:\n",
        "    dm.setup()\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Data setup failed: {e}\")\n",
        "\n",
        "num_classes = len(dm.train_ds.classes)\n",
        "print(\"Classes:\", dm.train_ds.classes)"
      ],
      "metadata": {
        "id": "hxGflZYZuZAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Preparing data module and model (this will error if your dataset path is wrong)...\")\n",
        "dm = PlantDataModule(EXTRACT_DIR, batch_size=BATCH_SIZE, img_size=224)\n",
        "\n",
        "try:\n",
        "    dm.setup()\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Data setup failed: {e}\")\n",
        "\n",
        "num_classes = len(dm.train_ds.classes)\n",
        "print(\"Classes:\", dm.train_ds.classes)\n",
        "\n",
        "model = TomatoHybridModel(num_classes=num_classes)"
      ],
      "metadata": {
        "id": "6GFezjfe3tLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoints = os.path.join(\n",
        "    os.getcwd(), \"checkpoints\", \"/content/drive/MyDrive/Project-1/best_model.pth\"\n",
        ")"
      ],
      "metadata": {
        "id": "RNOj4_QB3ZBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(checkpoints):\n",
        "    model.load_state_dict(torch.load(checkpoints))\n",
        "    print(\"Model loaded successfully from checkpoints.\")"
      ],
      "metadata": {
        "id": "SIPlR2sS3cmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = pl.Trainer(\n",
        "    max_epochs=15,\n",
        ")"
      ],
      "metadata": {
        "id": "17T7z1Lv39hY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2584dd3c"
      },
      "source": [
        "trainer.fit(model, dm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVE MODEL HERE\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Project-1/best_model.pth\"\n",
        "# Use the model's state_dict() for saving the raw weights\n",
        "torch.save(model.state_dict(), MODEL_PATH)\n",
        "print(\"Model saved at:\", MODEL_PATH)\n",
        "\n",
        "num_classes = len(dm.train_ds.classes)\n",
        "num_classes"
      ],
      "metadata": {
        "id": "W6xroyF94HCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.validate(model, dm)"
      ],
      "metadata": {
        "id": "9AAppHomHhvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you collected per-epoch averages â€” or just plot what you have\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Get max loss and accuracy values for y-axis limits\n",
        "max_loss = max(model.train_loss_history + model.val_loss_history)\n",
        "max_acc = max(model.train_acc_history + model.val_acc_history)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(model.train_loss_history,marker='o', linewidth=2, label=\"Train Loss\")\n",
        "plt.plot(model.val_loss_history,   marker='o', linewidth=2, label=\"Val Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.ylim(-0.02, 1.02)\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(model.train_acc_history, marker='o', linewidth=2, label=\"Train Accuracy\")\n",
        "plt.plot(model.val_acc_history,   marker='o', linewidth=2, label=\"Val Accuracy\")\n",
        "plt.ylim(0, 1.02)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training vs Validation Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wyrhJNyj3mgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model.eval()\n",
        "model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "test_dl = dm.test_dataloader()\n",
        "if test_dl is None:\n",
        "    print(\"No test set found â†’ using validation set\")\n",
        "    test_dl = dm.val_dataloader()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_dl:\n",
        "        x, y = batch\n",
        "        x = x.to(model.device)\n",
        "        logits = model(x)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(y.cpu().numpy())\n",
        "\n",
        "# Create & plot\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=dm.train_ds.classes)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "disp.plot(cmap='Blues', xticks_rotation=45)\n",
        "plt.title(\"Confusion Matrix (Test set)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Or with seaborn (nicer for many classes)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=dm.train_ds.classes,\n",
        "            yticklabels=dm.train_ds.classes)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9dq1WyEF3rJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install grad-cam"
      ],
      "metadata": {
        "id": "7hfrL1t_4eQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "#  Grad-CAM visualization for 3 images (SwinV2 + Lightning DataModule)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "#  Configuration\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "image_paths = [\n",
        "    \"/content/drive/MyDrive/BongoDev/Project-1/na1.jpg\",\n",
        "    \"/content/drive/MyDrive/BongoDev/Project-1/na.JPG\",\n",
        "    \"/content/drive/MyDrive/BongoDev/Project-1/na2.JPG\",\n",
        "]\n",
        "image_labels = [\"Sample 1\", \"Sample 2\", \"Sample 3\"]\n",
        "\n",
        "# Use patch embedding conv as target layer (SwinV2)\n",
        "# Corrected: TomatoHybridModel does not have a 'backbone' attribute,\n",
        "# instead it has specific components like 'swin', 'vit', 'efficientnet'.\n",
        "# We target a layer within the 'swin' component for Grad-CAM.\n",
        "target_layers = [model.swin.patch_embed.proj]\n",
        "\n",
        "# Device\n",
        "device = next(model.parameters()).device\n",
        "model.to(device).eval()\n",
        "\n",
        "# Grad-CAM object\n",
        "cam = GradCAM(model=model, target_layers=target_layers)\n",
        "\n",
        "# Validation transform\n",
        "val_transform = dm.val_tfms  # or define manually if dm is not defined\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "#  Visualization setup\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "fig, axes = plt.subplots(1, 3, figsize=(16, 6), dpi=130)\n",
        "fig.suptitle(\n",
        "    \"Grad-CAM: Where the Model is Looking (Arrow = Strongest Attention)\",\n",
        "    fontsize=16, fontweight='bold', y=1.04\n",
        ")\n",
        "\n",
        "for idx, (img_path, label) in enumerate(zip(image_paths, image_labels)):\n",
        "    ax = axes[idx]\n",
        "    try:\n",
        "        # Load image\n",
        "        img_pil = Image.open(img_path).convert(\"RGB\")\n",
        "        img_tensor = val_transform(img_pil).unsqueeze(0).to(device)\n",
        "\n",
        "        # Predict\n",
        "        with torch.no_grad():\n",
        "            logits = model(img_tensor)\n",
        "            pred_class_idx = logits.argmax(dim=1).item()\n",
        "            pred_class_name = dm.train_ds.classes[pred_class_idx]\n",
        "            confidence = torch.softmax(logits, dim=1)[0, pred_class_idx].item()\n",
        "\n",
        "        # Grad-CAM\n",
        "        targets = [ClassifierOutputTarget(pred_class_idx)]\n",
        "        grayscale_cam = cam(input_tensor=img_tensor, targets=targets)[0, :]\n",
        "\n",
        "        # Overlay heatmap (normalize correctly)\n",
        "        img_np = np.array(img_pil.resize((dm.img_size, dm.img_size))) / 255.0\n",
        "        visualization = show_cam_on_image(img_np, grayscale_cam, use_rgb=True)\n",
        "\n",
        "        # Find hotspot\n",
        "        max_y, max_x = np.unravel_index(np.argmax(grayscale_cam), grayscale_cam.shape)\n",
        "\n",
        "        # Plot image + heatmap\n",
        "        ax.imshow(visualization)\n",
        "\n",
        "        # Draw arrow safely\n",
        "        arrow_offset = 60\n",
        "        ax.annotate(\n",
        "            \"\",\n",
        "            xy=(max_x, max_y),\n",
        "            xytext=(min(max_x + arrow_offset, dm.img_size-1), max(max_y - arrow_offset, 0)),\n",
        "            arrowprops=dict(\n",
        "                facecolor='red',\n",
        "                edgecolor='darkred',\n",
        "                width=4,\n",
        "                headwidth=14,\n",
        "                headlength=18,\n",
        "                shrink=0.08,\n",
        "                alpha=0.9,\n",
        "                linewidth=1.5,\n",
        "                zorder=10\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Hotspot marker\n",
        "        ax.plot(max_x, max_y, marker='o', markersize=14,\n",
        "                color='red', markeredgecolor='white', markeredgewidth=2.5, zorder=11)\n",
        "\n",
        "        # Title with prediction info\n",
        "        ax.set_title(f\"{label}\\nPred: {pred_class_name}\\nConf: {confidence:.1%}\",\n",
        "                     fontsize=11, pad=12, fontweight='medium')\n",
        "        ax.axis('off')\n",
        "\n",
        "    except Exception as e:\n",
        "        ax.text(0.5, 0.5, f\"Error\\n{str(e)[:60]}...\", ha='center', va='center', color='red', fontsize=10)\n",
        "        ax.axis('off')\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DieBCu2senrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc"
      ],
      "metadata": {
        "id": "nT0-K_Y3smIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Ensure model is in evaluation mode and on the correct device\n",
        "model.eval()\n",
        "# Get the device the model is currently on (e.g., 'cuda' or 'cpu')\n",
        "model_device = next(model.parameters()).device\n",
        "model.to(model_device)\n",
        "\n",
        "all_labels = []\n",
        "all_logits = [] # Collect raw logits for ROC curve calculation\n",
        "\n",
        "# Determine which dataloader to use (validation or test)\n",
        "# The previous confusion matrix plot used test_dataloader first, then val_dataloader as fallback.\n",
        "current_dataloader = dm.test_dataloader()\n",
        "if current_dataloader is None:\n",
        "    print(\"No test set found, using validation set for ROC curve calculation.\")\n",
        "    current_dataloader = dm.val_dataloader()\n",
        "    if current_dataloader is None:\n",
        "        raise ValueError(\"Neither validation nor test dataloader is available. Cannot compute ROC curve.\")\n",
        "else:\n",
        "    print(\"Using test set for ROC curve calculation.\")\n",
        "\n",
        "with torch.no_grad(): # Disable gradient calculations for inference\n",
        "    for inputs, targets in current_dataloader:\n",
        "        inputs = inputs.to(model_device)\n",
        "        logits = model(inputs)\n",
        "        all_logits.append(logits.cpu())  # Move logits to CPU before appending\n",
        "        all_labels.append(targets.cpu()) # Move targets to CPU before appending\n",
        "\n",
        "# Concatenate all collected tensors into single NumPy arrays\n",
        "all_logits = torch.cat(all_logits).numpy()\n",
        "all_labels = torch.cat(all_labels).numpy()\n",
        "\n",
        "# Get number of classes from the data module\n",
        "num_classes = len(dm.train_ds.classes)\n",
        "class_names = dm.train_ds.classes # For plotting legends\n",
        "\n",
        "# Binarize the true labels (one-hot encode) for multiclass ROC calculation\n",
        "y_true = label_binarize(all_labels, classes=list(range(num_classes)))\n",
        "\n",
        "# Convert logits to probabilities using softmax for y_score\n",
        "y_score = torch.softmax(torch.tensor(all_logits), dim=1).numpy()\n",
        "\n",
        "print(f\"Collected {len(all_labels)} samples for ROC analysis.\")\n",
        "print(f\"Shape of y_true: {y_true.shape}\")\n",
        "print(f\"Shape of y_score: {y_score.shape}\")\n"
      ],
      "metadata": {
        "id": "GmkREjoysnnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "for i in range(num_classes):\n",
        "    fpr, tpr, _ = roc_curve(y_true[:, i], y_score[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.plot(\n",
        "        fpr,\n",
        "        tpr,\n",
        "        label=f\"Class {i} (AUC = {roc_auc:.3f})\"\n",
        "    )\n",
        "\n",
        "plt.plot([0, 1], [0, 1], \"k--\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"Multiclass ROC Curve\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JV8fGSNhs47v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, precision_recall_fscore_support\n",
        "import torch\n",
        "\n",
        "# ===============================================\n",
        "# Step 1: Collect predictions & true labels on test set\n",
        "# ===============================================\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "all_probs = []  # optional for ROC if needed later\n",
        "\n",
        "test_dl = dm.test_dataloader()  # or dm.val_dataloader() if no test set\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_dl:\n",
        "        x, y = batch\n",
        "        x = x.to(model.device)\n",
        "        logits = model(x)\n",
        "        probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
        "        preds = logits.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(y.cpu().numpy())\n",
        "        all_probs.extend(probs)\n",
        "\n",
        "# Convert to numpy arrays\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "all_probs = np.array(all_probs)\n",
        "\n",
        "class_names = dm.train_ds.classes  # your 10 class names\n",
        "\n",
        "# ===============================================\n",
        "# Step 2: Print Classification Report (Precision, Recall, F1)\n",
        "# ===============================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Classification Report (Precision, Recall, F1-Score)\")\n",
        "print(\"=\"*60)\n",
        "report = classification_report(all_labels, all_preds, target_names=class_names, digits=4)\n",
        "print(report)\n",
        "\n",
        "# ===============================================\n",
        "# Step 3: Per-class Precision, Recall, F1 Bar Plot\n",
        "# ===============================================\n",
        "precision, recall, f1, support = precision_recall_fscore_support(all_labels, all_preds, average=None)\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "x = np.arange(len(class_names))\n",
        "width = 0.25\n",
        "\n",
        "plt.bar(x - width, precision, width, label='Precision', color='skyblue')\n",
        "plt.bar(x, recall, width, label='Recall', color='lightgreen')\n",
        "plt.bar(x + width, f1, width, label='F1-Score', color='salmon')\n",
        "\n",
        "plt.xlabel('Classes')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Per-Class Precision, Recall & F1-Score')\n",
        "plt.xticks(x, class_names, rotation=45, ha='right')\n",
        "plt.legend()\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ===============================================\n",
        "# Step 4: Confusion Matrix (helps understand precision errors)\n",
        "# ===============================================\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "disp.plot(cmap='Blues', xticks_rotation=45)\n",
        "plt.title(\"Confusion Matrix (Test Set)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ===============================================\n",
        "# Step 5: Macro & Weighted Average Summary\n",
        "# ===============================================\n",
        "precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(all_labels, all_preds, average='macro')\n",
        "precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Summary Averages\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Macro Average    â†’ Precision: {precision_macro:.4f} | Recall: {recall_macro:.4f} | F1: {f1_macro:.4f}\")\n",
        "print(f\"Weighted Average â†’ Precision: {precision_weighted:.4f} | Recall: {recall_weighted:.4f} | F1: {f1_weighted:.4f}\")"
      ],
      "metadata": {
        "id": "8W2-44EAMmWX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}