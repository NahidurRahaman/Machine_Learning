{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-27T09:37:37.112270Z",
     "start_time": "2025-10-27T09:37:19.025742Z"
    }
   },
   "source": [
    "\"\"\"Class 16. Data Processing Pipeline using PyTorch\n",
    "\n",
    "Objectives:\n",
    "- Create a custom data processing pipeline using torch\n",
    "- Use torch builtin layers to create a deep feed forward neural network\n",
    "- Training techniques: Checkpointing, training, evaluation using torch\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch.nn as nn"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T09:37:01.053194500Z",
     "start_time": "2025-07-19T15:33:56.184866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "- Data Preparation stage (** TODAY's Focus)\n",
    "- Model Building stage\n",
    "- Training stage\n",
    "- Evaluation stage (Additional)\n",
    "- Deployment stage (Additional)\n",
    "- Monitoring stage (Additional)\n",
    "\"\"\"\n",
    "\n",
    "ROOT_DIR = \"E:\\\\PyCharmProjects\\\\pythonProject\\\\\"\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"data\")"
   ],
   "id": "6d34508c12c8af75",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T09:37:01.055190100Z",
     "start_time": "2025-07-19T15:33:56.222880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\" The data and the model must be onto the same device (either cpu or cuda)\n",
    "\"\"\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "id": "794a78fa7dba2651",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T09:37:01.058184800Z",
     "start_time": "2025-07-19T15:33:56.246767Z"
    }
   },
   "cell_type": "code",
   "source": "dataset_path = os.path.join(DATA_DIR, \"digit_train.csv\")",
   "id": "4170ccf3325479da",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T09:37:02.049584Z",
     "start_time": "2025-10-27T09:37:02.000699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv(dataset_path)\n",
    "data.head()"
   ],
   "id": "703302b26def5cd6",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m data = \u001B[43mpd\u001B[49m.read_csv(dataset_path)\n\u001B[32m      2\u001B[39m data.head()\n",
      "\u001B[31mNameError\u001B[39m: name 'pd' is not defined"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T15:50:16.670935Z",
     "start_time": "2025-07-19T15:50:16.658736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\" Split examples into feature and label \"\"\"\n",
    "idx = 3\n",
    "\n",
    "pixels = data.iloc[idx].values[1:].astype('float32')\n",
    "label = int(data.iloc[idx].values[0])\n",
    "\n",
    "print(pixels.shape)\n",
    "print(label)"
   ],
   "id": "e6d5e3c9203c4cd9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n",
      "4\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T15:50:17.684230Z",
     "start_time": "2025-07-19T15:50:17.670349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(type(pixels))\n",
    "print(type(label))"
   ],
   "id": "6f5d8a7d3cf5d668",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T15:50:20.026052Z",
     "start_time": "2025-07-19T15:50:20.013120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"Convert each features and label to tensor\"\"\"\n",
    "pixels = torch.tensor(pixels)\n",
    "label = torch.tensor(label)\n",
    "print(pixels[210:230])\n",
    "print(label)"
   ],
   "id": "d67cdb4c89c66640",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0.,   0.,   0.,  27., 254.,  63.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.])\n",
      "tensor(4)\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T15:52:32.213055Z",
     "start_time": "2025-07-19T15:52:32.196008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "  [[[1 2],\n",
    "   [3, 4]]] => (1, 2,2)\n",
    "\"\"\"\n",
    "pixels.reshape(28, 28).unsqueeze(0).shape"
   ],
   "id": "f76604322d92700b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T15:33:58.244346Z",
     "start_time": "2025-07-19T15:33:58.231185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\" \n",
    "Note 1: Torch process the data batchwise.\n",
    "So, we need to add a batch dimension (if not available)\n",
    "Example: pixels shape = (784,) => (B, 784)\n",
    "         labels shape = (1,) => (B, 1)\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "my_np_array = np.arange(12)\n",
    "my_np_array = my_np_array.reshape(-1, 12)\n",
    "print(my_np_array.shape)"
   ],
   "id": "41b8c18ca75ddcb7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 12)\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T15:33:58.260401Z",
     "start_time": "2025-07-19T15:33:58.246868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pixels = pixels.reshape(-1, 28, 28)\n",
    "print(pixels.shape)\n",
    "print(pixels[0, 17, 12])"
   ],
   "id": "a43f74014fcaa621",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "tensor(245.)\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T15:34:31.522059Z",
     "start_time": "2025-07-19T15:34:31.504929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pixels_transformation = transforms.Compose([\n",
    "    transforms.Normalize(\n",
    "        mean=torch.tensor([0.1307]), \n",
    "        std=torch.tensor([0.3081])),\n",
    "])\n",
    "pixels = pixels_transformation(pixels)"
   ],
   "id": "933a99275bf71170",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create a Dataset Class",
   "id": "24fc08207a2e71da"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T15:44:06.845144Z",
     "start_time": "2025-07-19T15:44:06.831061Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DigitDataset(Dataset):\n",
    "    def __init__(self, file_path, transform=None):\n",
    "        self.data = pd.read_csv(file_path)\n",
    "        print(data.head())\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of examples in the dataset\"\"\"\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\" Focus to process a single example in the dataset \"\"\"\n",
    "        pixels = self.data.iloc[idx].values[1:].astype('float32')\n",
    "        label = int(self.data.iloc[idx].values[0])\n",
    "\n",
    "        pixels = torch.tensor(pixels)\n",
    "        label = torch.tensor(label)\n",
    "\n",
    "        pixels = pixels.reshape(28, 28).unsqueeze(0) / 255.0\n",
    "        if self.transform:\n",
    "            pixels = pixels_transformation(pixels)\n",
    "\n",
    "        return pixels, label"
   ],
   "id": "ab62c20e5667cf58",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T15:44:11.884279Z",
     "start_time": "2025-07-19T15:44:09.869928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\" Concept of Dataset and Dataloader class\n",
    "\"\"\"\n",
    "dataset = DigitDataset(\n",
    "    file_path=dataset_path, \n",
    "    transform=pixels_transformation\n",
    ")"
   ],
   "id": "ad0c42c02ee7cde8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "0      1       0       0       0       0       0       0       0       0   \n",
      "1      0       0       0       0       0       0       0       0       0   \n",
      "2      1       0       0       0       0       0       0       0       0   \n",
      "3      4       0       0       0       0       0       0       0       0   \n",
      "4      0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
      "0       0  ...         0         0         0         0         0         0   \n",
      "1       0  ...         0         0         0         0         0         0   \n",
      "2       0  ...         0         0         0         0         0         0   \n",
      "3       0  ...         0         0         0         0         0         0   \n",
      "4       0  ...         0         0         0         0         0         0   \n",
      "\n",
      "   pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0  \n",
      "1         0         0         0         0  \n",
      "2         0         0         0         0  \n",
      "3         0         0         0         0  \n",
      "4         0         0         0         0  \n",
      "\n",
      "[5 rows x 785 columns]\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T07:35:47.094583Z",
     "start_time": "2025-10-27T07:35:41.170740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset=dataset, \n",
    "    lengths=[train_size, val_size, test_size],\n",
    "\n",
    ")"
   ],
   "id": "b0a87c378124f746",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Visual C++ Redistributable is not installed, this may lead to the DLL load failure.\n",
      "It can be downloaded at https://aka.ms/vs/16/release/vc_redist.x64.exe\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdata\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m random_split\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m \u001B[43mtorch\u001B[49m.manual_seed(\u001B[32m42\u001B[39m)\n\u001B[32m      5\u001B[39m train_size = \u001B[38;5;28mint\u001B[39m(\u001B[32m0.7\u001B[39m * \u001B[38;5;28mlen\u001B[39m(dataset))\n\u001B[32m      6\u001B[39m val_size = \u001B[38;5;28mint\u001B[39m(\u001B[32m0.15\u001B[39m * \u001B[38;5;28mlen\u001B[39m(dataset))\n",
      "\u001B[31mNameError\u001B[39m: name 'torch' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T16:18:45.843214Z",
     "start_time": "2025-07-19T16:18:45.821295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False, \n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    ")"
   ],
   "id": "99eac08be53b7b19",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T16:21:46.631544Z",
     "start_time": "2025-07-19T16:21:46.162420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "1 is the chanel dimension i.e. grayscale no of channel is 1, RGB it is 3\n",
    "pixels (B, C, H, W)\n",
    "torch.Size([32, 1, 28, 28])\n",
    "\"\"\"\n",
    "for pixel_batch, label_batch in train_loader:\n",
    "    print(pixel_batch.shape)\n",
    "    print(label_batch.shape)\n",
    "    print(label_batch)\n",
    "    break"
   ],
   "id": "2e633946d17214b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32])\n",
      "tensor([7, 4, 2, 0, 0, 4, 6, 3, 2, 3, 2, 9, 7, 5, 0, 2, 0, 6, 4, 6, 7, 3, 3, 4,\n",
      "        1, 9, 2, 3, 9, 0, 6, 9])\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model",
   "id": "d757fecad7781d08"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T16:25:21.281453Z",
     "start_time": "2025-07-19T16:25:21.259181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DigitClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DigitClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ],
   "id": "172b14212ab7670a",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T16:25:33.842353Z",
     "start_time": "2025-07-19T16:25:33.827305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_model(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(data_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            accuracy += (predicted == target).sum().item()\n",
    "        \n",
    "        val_loss /= len(data_loader.dataset)\n",
    "        accuracy /= len(data_loader.dataset)\n",
    "    return val_loss, accuracy"
   ],
   "id": "f4962d7aeee50d80",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T16:46:16.635513Z",
     "start_time": "2025-07-19T16:46:16.623946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(\n",
    "        model, \n",
    "        train_loader, val_loader, \n",
    "        criterion, optimizer, \n",
    "        num_epochs, \n",
    "        device,\n",
    "        checkpoint_path\n",
    "):\n",
    "    model.train()\n",
    "    \n",
    "    best_val_accuracy = 0\n",
    "    patience = 3\n",
    "    \n",
    "    # Checkpoints\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0\n",
    "        for batch_idx, (pixel_batch, label_batch) in enumerate(train_loader):\n",
    "            pixel_batch, label_batch = pixel_batch.to(device), label_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, label_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()    \n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader.dataset) \n",
    "        val_loss, val_accuracy = evaluate_model(\n",
    "            model=model,\n",
    "            data_loader=val_loader,\n",
    "            criterion=criterion,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(\"Best parameter so far.\")\n",
    "        else:\n",
    "            \"\"\" early stopping \"\"\"\n",
    "            patience = patience - 1\n",
    "        \n",
    "        print(f\"epoch [{epoch+1}/{num_epochs}], loss: {train_loss:.4f}\", end=\" \")\n",
    "        print(f\"val_loss: {val_loss:.4f}\", end=\" \")\n",
    "        print(f\"val_acc: {val_accuracy:.4f}\")\n",
    "        \n",
    "        if patience == 0:\n",
    "            \"\"\" Callback: Early stopping \"\"\"\n",
    "            print(f\"Model performance is not improving. Exiting the training.\")\n",
    "            break"
   ],
   "id": "4dcc1627b248b7d6",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T16:33:13.978288Z",
     "start_time": "2025-07-19T16:33:11.977398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = DigitClassifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ],
   "id": "2d79a0d187232fc6",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T16:33:24.741296Z",
     "start_time": "2025-07-19T16:33:24.727580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "checkpoint_path = os.path.join(\n",
    "    os.getcwd(), \"checkpoints\", \"best_model.pth\"\n",
    ")"
   ],
   "id": "7f260bbb5d9683b8",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T16:33:43.351674Z",
     "start_time": "2025-07-19T16:33:43.342537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if os.path.exists(checkpoint_path):\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    print(\"Model loaded successfully from checkpoints.\")"
   ],
   "id": "9d0f4c26bbcf04b0",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T16:34:55.920528Z",
     "start_time": "2025-07-19T16:34:02.415218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=100,\n",
    "    device=device,\n",
    "    checkpoint_path=checkpoint_path,\n",
    ")"
   ],
   "id": "c4f02ed4a45cdb9b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter so far.\n",
      "epoch [1/100], loss: 0.0102 val_loss: 0.0052 val_acc: 0.9500\n",
      "Best parameter so far.\n",
      "epoch [2/100], loss: 0.0045 val_loss: 0.0040 val_acc: 0.9603\n",
      "Best parameter so far.\n",
      "epoch [3/100], loss: 0.0032 val_loss: 0.0031 val_acc: 0.9695\n",
      "epoch [4/100], loss: 0.0024 val_loss: 0.0034 val_acc: 0.9659\n",
      "Model performance is not improving. Exiting the training.\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluate Performance",
   "id": "faf30cf791944157"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T16:36:25.393251Z",
     "start_time": "2025-07-19T16:36:23.250411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.load_state_dict(torch.load(checkpoint_path))\n",
    "\n",
    "val_loss, val_acc = evaluate_model(\n",
    "    model=model,\n",
    "    data_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"test_loss: {val_loss:0.4f}, test_acc: {val_acc:0.4f}\")"
   ],
   "id": "4947265261803968",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.0031, test_acc: 0.9695\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T16:36:37.168274Z",
     "start_time": "2025-07-19T16:36:35.126463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_loss, test_accuracy = evaluate_model(\n",
    "    model=model,\n",
    "    data_loader=test_loader,\n",
    "    criterion=criterion,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"test_loss: {test_loss:0.4f}, test_acc: {test_accuracy:0.4f}\")"
   ],
   "id": "47293d19f8b7d5b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.0042, test_acc: 0.9603\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Bonus",
   "id": "26ff22e7cd572299"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T16:38:14.115688Z",
     "start_time": "2025-07-19T16:37:17.195158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train = np.array([data[0].numpy().flatten() for data in train_dataset])\n",
    "y_train = np.array([data[1] for data in train_dataset])\n",
    "X_test = np.array([data[0].numpy().flatten() for data in test_dataset])\n",
    "y_test = np.array([data[1] for data in test_dataset])\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'DecisionTreeClassifier test accuracy: {accuracy:.2f}')"
   ],
   "id": "96966cd0f5a0ceb9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier test accuracy: 0.85\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8b9c52428e1e254c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
