{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-03T14:06:05.083100Z",
     "start_time": "2025-10-03T14:06:03.026523Z"
    }
   },
   "source": [
    "\"\"\"Class 14. Multilayer Perceptron and backpropagation\n",
    "\n",
    "Objectives:\n",
    "1. Understand deep feed forward network\n",
    "2. How backpropagation works\n",
    "3. Implement a deep feed forward network using PyTorch\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T14:06:09.772692Z",
     "start_time": "2025-10-03T14:06:09.764642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\" Deep Neural Network\n",
    "1. Deep Feedforward network: data is passed only in the forward direction layerwise\n",
    "2. Recurrent Neural Network: data can passed any layer to any layer.\n",
    "\"\"\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "id": "8e7a5c4ac7a2c6eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Pipeline",
   "id": "ab9b9dc435624e2f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T14:06:23.351358Z",
     "start_time": "2025-10-03T14:06:23.341061Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Image: A 2D matrix of pixel values.\n",
    "Color Channels: \n",
    "  - Grayscale image has 1 channel per pixel. For a pixel color between (0-255)\n",
    "  - RGB image has 3 channels per pixel. For a pixel (0-255, 0-255, 0-255) => (128, 247, 18)\n",
    "\"\"\"\n",
    "# Preprocessing pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=(0.1307,),\n",
    "        std=(0.3081,)\n",
    "    )\n",
    "])"
   ],
   "id": "7366637201a33442",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T14:07:37.629625Z",
     "start_time": "2025-10-03T14:07:37.612217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Download dataset\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='C:\\Users\\Loccha kakko\\PyCharmMiscProject\\machine_learning',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root= 'C:\\Users\\Loccha kakko\\PyCharmMiscProject\\machine_learning',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")"
   ],
   "id": "f326c7a7a943dd04",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (3936338690.py, line 4)",
     "output_type": "error",
     "traceback": [
      "  \u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[31m    \u001B[39m\u001B[31mroot='C:\\Users\\Loccha kakko\\PyCharmMiscProject\\machine_learning',\u001B[39m\n         ^\n\u001B[31mSyntaxError\u001B[39m\u001B[31m:\u001B[39m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T16:09:32.112911Z",
     "start_time": "2025-07-18T16:09:32.099354Z"
    }
   },
   "cell_type": "code",
   "source": "print(type(train_data))",
   "id": "373e67f0fbea42e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.datasets.mnist.MNIST'>\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T16:11:11.704280Z",
     "start_time": "2025-07-18T16:11:11.695249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "MNIST: Hand written digit recognition dataset\n",
    "Trainset contains 60000 images\n",
    "Each image is 28x28 in shape\n",
    "So there is 784 pixels for each image\n",
    "\n",
    "We are given 785 columns for each image\n",
    "X: column 1-784 (pixels)\n",
    "y: cloumn 785 (digits)\n",
    "\n",
    "\n",
    "Understand Batch Size:\n",
    "\n",
    "We have 60000 images\n",
    "We calculate logits for each images \n",
    "Calulcate gradients\n",
    "Update the weights\n",
    "\n",
    "Now if we have 10 epoch and in each epoch we calculate logits for 60000 images\n",
    "Then 10 x 60000 = 600000 unit\n",
    "\n",
    "A batch size is a random sample from the training set.\n",
    "batch size 32, 64, 128\n",
    "\n",
    "We have total 60000 training images\n",
    "For example everytime we select only 100 images (Batch size).\n",
    "So, total batches = 60000 / 100 = 600 batches\n",
    "For this batch we will calculate logits, compute gradient and update weights (Step)\n",
    "\n",
    "for epoch in epochs:\n",
    "    batches = [batch1, batch2, ...batch600]\n",
    "    for each step in steps:\n",
    "         We calculate logits for each images \n",
    "         Calulcate gradients\n",
    "         Update the weights\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# loads data one batch at a time into the memory\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    ")"
   ],
   "id": "ddc10de768d90a75",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T16:11:21.918904Z",
     "start_time": "2025-07-18T16:11:21.907373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Perceptron(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.w = nn.Parameter(torch.randn(input_size))\n",
    "        self.b = nn.Parameter(torch.randn(1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x @ self.w + self.b\n",
    "        return x"
   ],
   "id": "a13b0b74585ab7f0",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T16:16:55.757347Z",
     "start_time": "2025-07-18T16:16:55.740038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_size = 28 * 28\n",
    "sample_input = torch.randn(input_size)\n",
    "\n",
    "perceptron = Perceptron(input_size)\n",
    "output = perceptron(sample_input)\n",
    "print(output)"
   ],
   "id": "52913e251d6c8ac3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-9.3480], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T16:17:00.451798Z",
     "start_time": "2025-07-18T16:17:00.438257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\" \n",
    "Activation function: ReLU (Rectified Linear Unit)\n",
    "function: relu(z) = max(0, z)\n",
    "\"\"\"\n",
    "\n",
    "class ReLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReLU, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.maximum(torch.tensor(0.0), x)\n",
    "    "
   ],
   "id": "835ba9b3427cb1ee",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T16:17:00.933553Z",
     "start_time": "2025-07-18T16:17:00.919962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "relu = ReLU()\n",
    "output = relu(output)\n",
    "print(output)"
   ],
   "id": "5e3c3595e17f6f3b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.], grad_fn=<MaximumBackward0>)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T16:24:16.378109Z",
     "start_time": "2025-07-18T16:24:16.357769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Linear, self).__init__()\n",
    "        \n",
    "        self.perceptrons = nn.ModuleList([\n",
    "            Perceptron(input_size) for _ in range(output_size)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outputs = [\n",
    "            perceptron(x) for perceptron in self.perceptrons\n",
    "        ]\n",
    "        outputs = torch.stack(outputs, dim=1)\n",
    "        return outputs"
   ],
   "id": "9273f1570eba5bef",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T16:26:00.573869Z",
     "start_time": "2025-07-18T16:26:00.565827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "linear = Linear(input_size, 3)\n",
    "output = linear(sample_input)\n",
    "print(output.shape)"
   ],
   "id": "d4c0a162eeb95501",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T16:35:08.590114Z",
     "start_time": "2025-07-18T16:35:08.577142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DigitClassifier(nn.Module):\n",
    "    def __init__(self, input_size=28 * 28, output_size=10):\n",
    "        super(DigitClassifier, self).__init__()\n",
    "        self.fc1 = Linear(input_size, 256)\n",
    "        self.fc2 = Linear(256, 128)\n",
    "        self.fc3 = Linear(128, output_size)\n",
    "        self.relu = ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Let say x = [1, 2, 3, ....]   shape:  [784]\n",
    "        x = x.view(-1, input_size)\n",
    "        # Let say x = [1, 2, 3, ....]   shape:  [1, 784]\n",
    "        x = self.fc1(x)\n",
    "        # Let say x = [-1, 2.2, 3.3, ...]   shape:  [1, 128]\n",
    "        x = self.relu(x)\n",
    "        # Let say x = [0, 2.2, 3.3, ...]   shape:  [1, 128]\n",
    "        x = self.fc2(x)\n",
    "        # Let say x = [-.50, 4.2, -3.3, ...]   shape:  [1, 64]\n",
    "        x = self.relu(x)\n",
    "        # Let say x = [0, 4.2, 0, ...]   shape:  [1, 64]\n",
    "        x = self.fc3(x)\n",
    "        # Let say x = [5, -4.2, .3, ...]   shape:  [1, 10]\n",
    "        return x"
   ],
   "id": "8f8914c15a19f54",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T16:35:09.508443Z",
     "start_time": "2025-07-18T16:35:09.405739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = DigitClassifier(input_size=28 * 28, output_size=10).to(device)\n",
    "sample_input = sample_input.to(device)\n",
    "\n",
    "output = model(sample_input)\n",
    "print(output.shape)\n",
    "print(output)"
   ],
   "id": "f648c90b2ab393cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n",
      "tensor([[ -716.5026, -1683.2001,  1311.7974,  1034.5662,  1836.6747,   535.4442,\n",
      "          -678.9324, -1437.9171,  -224.9353, -2418.5049]], device='cuda:0',\n",
      "       grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T16:35:10.566017Z",
     "start_time": "2025-07-18T16:35:10.548675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(output)\n",
    "\n",
    "_, predicted = torch.max(output, 1)\n",
    "print(\"Class label:\", predicted)"
   ],
   "id": "7db9461b4cc071d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -716.5026, -1683.2001,  1311.7974,  1034.5662,  1836.6747,   535.4442,\n",
      "          -678.9324, -1437.9171,  -224.9353, -2418.5049]], device='cuda:0',\n",
      "       grad_fn=<StackBackward0>)\n",
      "Class label: tensor([4], device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T16:35:11.560911Z",
     "start_time": "2025-07-18T16:35:11.547856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "id": "6d8b1eee8c6374b1",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T16:42:04.937650Z",
     "start_time": "2025-07-18T16:35:11.939743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = 2\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")"
   ],
   "id": "a7c9c909652f2434",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [1/938], Loss: 4287.7012\n",
      "Epoch [1/2], Step [101/938], Loss: 480.1638\n",
      "Epoch [1/2], Step [201/938], Loss: 386.3238\n",
      "Epoch [1/2], Step [301/938], Loss: 318.1131\n",
      "Epoch [1/2], Step [401/938], Loss: 156.4583\n",
      "Epoch [1/2], Step [501/938], Loss: 83.3444\n",
      "Epoch [1/2], Step [601/938], Loss: 146.2842\n",
      "Epoch [1/2], Step [701/938], Loss: 151.8065\n",
      "Epoch [1/2], Step [801/938], Loss: 34.2748\n",
      "Epoch [1/2], Step [901/938], Loss: 25.7679\n",
      "Epoch 1, Loss: 277.03577635079813\n",
      "Epoch [2/2], Step [1/938], Loss: 74.6780\n",
      "Epoch [2/2], Step [101/938], Loss: 169.3121\n",
      "Epoch [2/2], Step [201/938], Loss: 23.9952\n",
      "Epoch [2/2], Step [301/938], Loss: 66.5253\n",
      "Epoch [2/2], Step [401/938], Loss: 46.6273\n",
      "Epoch [2/2], Step [501/938], Loss: 53.3300\n",
      "Epoch [2/2], Step [601/938], Loss: 47.1615\n",
      "Epoch [2/2], Step [701/938], Loss: 122.5683\n",
      "Epoch [2/2], Step [801/938], Loss: 53.4044\n",
      "Epoch [2/2], Step [901/938], Loss: 105.3979\n",
      "Epoch 2, Loss: 67.89323507112735\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T16:45:02.457761Z",
     "start_time": "2025-07-18T16:44:55.089484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on the test set: {accuracy:.2f}%')"
   ],
   "id": "dca37939b8c5cd8f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 89.84%\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a3f6960790087fd2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
